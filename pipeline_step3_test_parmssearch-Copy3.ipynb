{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK pyradiomics neuroCombat MLstatkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWbxJ8q-rWDn",
        "outputId": "070090f1-96a2-4a70-cb17-9688df23b51c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: pyradiomics in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: neuroCombat in /usr/local/lib/python3.11/dist-packages (0.2.12)\n",
            "Collecting MLstatkit\n",
            "  Downloading MLstatkit-0.1.7-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from pyradiomics) (1.26.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pyradiomics) (1.8.0)\n",
            "Requirement already satisfied: pykwalify>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from pyradiomics) (1.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from pyradiomics) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from MLstatkit) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from MLstatkit) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from MLstatkit) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from MLstatkit) (4.67.1)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from pykwalify>=1.6.0->pyradiomics) (0.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from pykwalify>=1.6.0->pyradiomics) (2.8.2)\n",
            "Requirement already satisfied: ruamel.yaml>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from pykwalify>=1.6.0->pyradiomics) (0.18.10)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->MLstatkit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->MLstatkit) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->MLstatkit) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->MLstatkit) (3.5.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.16.0->pykwalify>=1.6.0->pyradiomics) (0.2.12)\n",
            "Downloading MLstatkit-0.1.7-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: MLstatkit\n",
            "Successfully installed MLstatkit-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tfTniUZ8rJYs"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import logging\n",
        "import pandas\n",
        "import SimpleITK as sitk\n",
        "import radiomics\n",
        "import re\n",
        "import pickle\n",
        "import math\n",
        "from radiomics import featureextractor\n",
        "from neuroCombat import neuroCombat\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import auc\n",
        "#from sklearn.metrics import plot_roc_curve\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import svm\n",
        "from sklearn import linear_model\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import shutil\n",
        "from scipy import stats\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from MLstatkit.stats import Delong_test as delong\n",
        "#import delong.delong as delong\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from scipy.stats import mannwhitneyu\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pscMmoZerJYt"
      },
      "outputs": [],
      "source": [
        "#run properly first to check, then add delongs, then check for segs of difficult cases and add as 4th dataset\n",
        "#for difficult cases treat as fourth set to see what maintains performance\n",
        "#add way of saving individual diagnosis? one big spread sheet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPFOkyDFrJYt"
      },
      "outputs": [],
      "source": [
        "# back up incase grid search doesnt work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SYr2MjekrJYt",
        "outputId": "cf119f27-5953-4c4e-b6d2-0ef1f00f5933"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/Users/mnlmd/Documents/PyradiomicsResults/20250201/20250201-183149'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "home=\"/Users/mnlmd/Documents/PyradiomicsResults/\"\n",
        "\n",
        "if not os.path.exists(home):\n",
        "  os.makedirs(home)\n",
        "else:\n",
        "  pass\n",
        "if not os.path.exists(os.path.join(home,\"Template\")):\n",
        "  os.makedirs(os.path.join(home,\"Template\"))\n",
        "else:\n",
        "  pass\n",
        "temp=os.path.join(home,\"Template\")\n",
        "Date_folder = datetime.datetime.today().strftime ('%Y%m%d')\n",
        "Datetime_folder = datetime.datetime.today().strftime ('%Y%m%d-%H%M%S')\n",
        "path=os.path.join(home,Date_folder, Datetime_folder)\n",
        "shutil.copytree(temp,path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bt807rmsrJYu"
      },
      "outputs": [],
      "source": [
        "import nbconvert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E4Lyn_lOrJYu",
        "outputId": "0d25c71a-a8fe-482f-efb9-ee0a22434fb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This application is used to convert notebook files (*.ipynb)\n",
            "        to various other formats.\n",
            "\n",
            "        WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "=======\n",
            "The options below are convenience aliases to configurable class-options,\n",
            "as listed in the \"Equivalent to\" description-line of the aliases.\n",
            "To see all configurable class-options for some <cmd>, use:\n",
            "    <cmd> --help-all\n",
            "\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "    Equivalent to: [--Application.log_level=10]\n",
            "--show-config\n",
            "    Show the application's configuration (human-readable format)\n",
            "    Equivalent to: [--Application.show_config=True]\n",
            "--show-config-json\n",
            "    Show the application's configuration (json format)\n",
            "    Equivalent to: [--Application.show_config_json=True]\n",
            "--generate-config\n",
            "    generate default config file\n",
            "    Equivalent to: [--JupyterApp.generate_config=True]\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "    Equivalent to: [--JupyterApp.answer_yes=True]\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "    Equivalent to: [--ExecutePreprocessor.enabled=True]\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "    Equivalent to: [--ExecutePreprocessor.allow_errors=True]\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "    Equivalent to: [--NbConvertApp.from_stdin=True]\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "    Equivalent to: [--NbConvertApp.writer_class=StdoutWriter]\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only\n",
            "            relevant when converting to notebook format)\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory=]\n",
            "--clear-output\n",
            "    Clear output of current file and save in place,\n",
            "            overwriting the existing notebook.\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --ClearOutputPreprocessor.enabled=True]\n",
            "--coalesce-streams\n",
            "    Coalesce consecutive stdout and stderr outputs into one stream (within each cell).\n",
            "    Equivalent to: [--NbConvertApp.use_output_suffix=False --NbConvertApp.export_format=notebook --FilesWriter.build_directory= --CoalesceStreamsPreprocessor.enabled=True]\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input_prompt=True --TemplateExporter.exclude_output_prompt=True]\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document.\n",
            "            This mode is ideal for generating code-free reports.\n",
            "    Equivalent to: [--TemplateExporter.exclude_output_prompt=True --TemplateExporter.exclude_input=True --TemplateExporter.exclude_input_prompt=True]\n",
            "--allow-chromium-download\n",
            "    Whether to allow downloading chromium if no suitable version is found on the system.\n",
            "    Equivalent to: [--WebPDFExporter.allow_chromium_download=True]\n",
            "--disable-chromium-sandbox\n",
            "    Disable chromium security sandbox when converting to PDF..\n",
            "    Equivalent to: [--WebPDFExporter.disable_sandbox=True]\n",
            "--show-input\n",
            "    Shows code input. This flag is only useful for dejavu users.\n",
            "    Equivalent to: [--TemplateExporter.exclude_input=False]\n",
            "--embed-images\n",
            "    Embed the images as base64 dataurls in the output. This flag is only useful for the HTML/WebPDF/Slides exports.\n",
            "    Equivalent to: [--HTMLExporter.embed_images=True]\n",
            "--sanitize-html\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized..\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html=True]\n",
            "--log-level=<Enum>\n",
            "    Set the log level by value or name.\n",
            "    Choices: any of [0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL']\n",
            "    Default: 30\n",
            "    Equivalent to: [--Application.log_level]\n",
            "--config=<Unicode>\n",
            "    Full path of a config file.\n",
            "    Default: ''\n",
            "    Equivalent to: [--JupyterApp.config_file]\n",
            "--to=<Unicode>\n",
            "    The export format to be used, either one of the built-in formats\n",
            "            ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf']\n",
            "            or a dotted object name that represents the import path for an\n",
            "            ``Exporter`` class\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.export_format]\n",
            "--template=<Unicode>\n",
            "    Name of the template to use\n",
            "    Default: ''\n",
            "    Equivalent to: [--TemplateExporter.template_name]\n",
            "--template-file=<Unicode>\n",
            "    Name of the template file to use\n",
            "    Default: None\n",
            "    Equivalent to: [--TemplateExporter.template_file]\n",
            "--theme=<Unicode>\n",
            "    Template specific theme(e.g. the name of a JupyterLab CSS theme distributed\n",
            "    as prebuilt extension for the lab template)\n",
            "    Default: 'light'\n",
            "    Equivalent to: [--HTMLExporter.theme]\n",
            "--sanitize_html=<Bool>\n",
            "    Whether the HTML in Markdown cells and cell outputs should be sanitized.This\n",
            "    should be set to True by nbviewer or similar tools.\n",
            "    Default: False\n",
            "    Equivalent to: [--HTMLExporter.sanitize_html]\n",
            "--writer=<DottedObjectName>\n",
            "    Writer class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: 'FilesWriter'\n",
            "    Equivalent to: [--NbConvertApp.writer_class]\n",
            "--post=<DottedOrNone>\n",
            "    PostProcessor class used to write the\n",
            "                                        results of the conversion\n",
            "    Default: ''\n",
            "    Equivalent to: [--NbConvertApp.postprocessor_class]\n",
            "--output=<Unicode>\n",
            "    Overwrite base name use for output files.\n",
            "                Supports pattern replacements '{notebook_name}'.\n",
            "    Default: '{notebook_name}'\n",
            "    Equivalent to: [--NbConvertApp.output_base]\n",
            "--output-dir=<Unicode>\n",
            "    Directory to write output(s) to. Defaults\n",
            "                                  to output to the directory of each notebook. To recover\n",
            "                                  previous default behaviour (outputting to the current\n",
            "                                  working directory) use . as the flag value.\n",
            "    Default: ''\n",
            "    Equivalent to: [--FilesWriter.build_directory]\n",
            "--reveal-prefix=<Unicode>\n",
            "    The URL prefix for reveal.js (version 3.x).\n",
            "            This defaults to the reveal CDN, but can be any url pointing to a copy\n",
            "            of reveal.js.\n",
            "            For speaker notes to work, this must be a relative path to a local\n",
            "            copy of reveal.js: e.g., \"reveal.js\".\n",
            "            If a relative path is given, it must be a subdirectory of the\n",
            "            current directory (from which the server is run).\n",
            "            See the usage documentation\n",
            "            (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-slideshow)\n",
            "            for more details.\n",
            "    Default: ''\n",
            "    Equivalent to: [--SlidesExporter.reveal_url_prefix]\n",
            "--nbformat=<Enum>\n",
            "    The nbformat version to write.\n",
            "            Use this to downgrade notebooks.\n",
            "    Choices: any of [1, 2, 3, 4]\n",
            "    Default: 4\n",
            "    Equivalent to: [--NotebookExporter.nbformat_version]\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to html\n",
            "\n",
            "            Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'qtpdf', 'qtpng', 'rst', 'script', 'slides', 'webpdf'].\n",
            "\n",
            "            > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "\n",
            "            Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "            'base', 'article' and 'report'.  HTML includes 'basic', 'lab' and\n",
            "            'classic'. You can specify the flavor of the format used.\n",
            "\n",
            "            > jupyter nbconvert --to html --template lab mynotebook.ipynb\n",
            "\n",
            "            You can also pipe the output to stdout, rather than a file\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "\n",
            "            PDF is generated via latex\n",
            "\n",
            "            > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "\n",
            "            You can get (and serve) a Reveal.js-powered slideshow\n",
            "\n",
            "            > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "\n",
            "            Multiple notebooks can be given at the command line in a couple of\n",
            "            different ways:\n",
            "\n",
            "            > jupyter nbconvert notebook*.ipynb\n",
            "            > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "\n",
            "            or you can specify the notebooks list in a config file, containing::\n",
            "\n",
            "                c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "\n",
            "            > jupyter nbconvert --config mycfg.py\n",
            "\n",
            "To see all available configurables, use `--help-all`.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[NbConvertApp] WARNING | pattern 'pipeline_step3_test_parmssearch.ipynb' matched no files\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b'\\njupyter nbconvert --to html pipeline_step3_test_parmssearch.ipynb\\n'' returned non-zero exit status 255.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-edd729ac9b5a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\njupyter nbconvert --to html pipeline_step3_test_parmssearch.ipynb\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\njupyter nbconvert --to html pipeline_step3_test_parmssearch.ipynb\\n'' returned non-zero exit status 255."
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "\n",
        "jupyter nbconvert --to html pipeline_step3_test_parmssearch.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "bs63n-NgrJYu",
        "outputId": "dd67f11e-5a22-4d77-acbe-4a8ecf76ac88"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/Users/mnlmd/Documents/PyradiomicsResults/Template_cpu/pipeline_step3_test_parmssearch.html'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mnlmd/Documents/PyradiomicsResults/Template_cpu/pipeline_step3_test_parmssearch.html' -> '/Users/mnlmd/Documents/PyradiomicsResults/20250201/20250201-183149/20250201start_pipeline_step3_test_parmssearch.html'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ceec25221632>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Template_cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"pipeline_step3_test_parmssearch.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mnlmd/Documents/PyradiomicsResults/Template_cpu/pipeline_step3_test_parmssearch.html'"
          ]
        }
      ],
      "source": [
        "d_path= path\n",
        "\n",
        "dest=os.path.join(d_path,str(Date_folder)+\"start_pipeline_step3_test_parmssearch.html\")\n",
        "home=\"/Users/mnlmd/Documents/PyradiomicsResults/\"\n",
        "\n",
        "temp=os.path.join(home,\"Template_cpu\")\n",
        "source = os.path.join(temp,\"pipeline_step3_test_parmssearch.html\")\n",
        "shutil.move(source, dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qVNih9qrJYu"
      },
      "outputs": [],
      "source": [
        "# fix these when training finished\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXrPlU5TrJYu"
      },
      "outputs": [],
      "source": [
        "icsv=pandas.read_csv(\"/Users/mnlmd/Documents/pyradinputnov22_3.csv\")\n",
        "\n",
        "y=icsv.iloc[1,0]\n",
        "imtest=sitk.ReadImage(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQl7I3JQrJYu"
      },
      "outputs": [],
      "source": [
        "print(y)\n",
        "print(imtest.GetOrigin())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTybDAWHrJYu"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    outPath = path\n",
        "#     change to path_output from pipeline step 2, could change 2020_05_09 to an input cmd variable and add it to file names below\n",
        "\n",
        "    inputCSV = \"/Users/mnlmd/Documents/pyradinputnov22_3.csv\"\n",
        "    outputFilepath = os.path.join(outPath, 'radiomics_features_pd_' +str(Date_folder)+'.csv')\n",
        "    progress_filename = os.path.join(outPath, 'pyrad_log.txt')\n",
        "    params = os.path.join(outPath, 'Params.yaml')\n",
        "\n",
        "  # Configure logging\n",
        "    rLogger = logging.getLogger('radiomics')\n",
        "\n",
        "  # Set logging level\n",
        "  # rLogger.setLevel(logging.INFO)  # Not needed, default log level of logger is INFO\n",
        "\n",
        "  # Create handler for writing to log file\n",
        "    handler = logging.FileHandler(filename=progress_filename, mode='w')\n",
        "    handler.setFormatter(logging.Formatter('%(levelname)s:%(name)s: %(message)s'))\n",
        "    rLogger.addHandler(handler)\n",
        "\n",
        "  # Initialize logging for batch log messages\n",
        "    logger = rLogger.getChild('batch')\n",
        "\n",
        "  # Set verbosity level for output to stderr (default level = WARNING)\n",
        "    radiomics.setVerbosity(logging.INFO)\n",
        "\n",
        "    logger.info('pyradiomics version: %s', radiomics.__version__)\n",
        "    logger.info('Loading CSV')\n",
        "\n",
        "  # ####### Up to this point, this script is equal to the 'regular' batchprocessing script ########\n",
        "\n",
        "    try:\n",
        "    # Use pandas to read and transpose ('.T') the input data\n",
        "    # The transposition is needed so that each column represents one test case. This is easier for iteration over\n",
        "    # the input cases\n",
        "        flists = pandas.read_csv(inputCSV).T\n",
        "    except Exception:\n",
        "        logger.error('CSV READ FAILED', exc_info=True)\n",
        "        exit(-1)\n",
        "\n",
        "    logger.info('Loading Done')\n",
        "    logger.info('Patients: %d', len(flists.columns))\n",
        "\n",
        "    if os.path.isfile(params):\n",
        "        extractor = featureextractor.RadiomicsFeatureExtractor(params)\n",
        "    else:  # Parameter file not found, use hardcoded settings instead\n",
        "        settings = {}\n",
        "        settings['binWidth'] = 0.075\n",
        "        settings['resampledPixelSpacing'] = [4,4,4]\n",
        "        settings['interpolator'] = sitk.sitkBSpline\n",
        "        settings['enableCExtensions'] = True\n",
        "\n",
        "        extractor = featureextractor.RadiomicsFeatureExtractor(**settings)\n",
        "    # extractor.enableInputImages(wavelet= {'level': 2})\n",
        "\n",
        "    logger.info('Enabled input images types: %s', extractor.enabledImagetypes)\n",
        "    logger.info('Enabled features: %s', extractor.enabledFeatures)\n",
        "    logger.info('Current settings: %s', extractor.settings)\n",
        "\n",
        "  # Instantiate a pandas data frame to hold the results of all patients\n",
        "    results = pandas.DataFrame()\n",
        "\n",
        "    for entry in flists:  # Loop over all columns (i.e. the test cases)\n",
        "        logger.info(\"(%d/%d) Processing Patient (Image: %s, Mask: %s)\",\n",
        "                    entry + 1,\n",
        "                    len(flists),\n",
        "                    flists[entry]['Image'],\n",
        "                    flists[entry]['Mask'])\n",
        "\n",
        "        imageFilepath = flists[entry]['Image']\n",
        "        maskFilepath = flists[entry]['Mask']\n",
        "        label = flists[entry].get('Label', None)\n",
        "\n",
        "        if str(label).isdigit():\n",
        "            label = int(label)\n",
        "        else:\n",
        "            label = None\n",
        "\n",
        "        if (imageFilepath is not None) and (maskFilepath is not None):\n",
        "            featureVector = flists[entry]  # This is a pandas Series\n",
        "            featureVector['Image'] = os.path.basename(imageFilepath)\n",
        "            featureVector['Mask'] = os.path.basename(maskFilepath)\n",
        "\n",
        "            try:\n",
        "        # PyRadiomics returns the result as an ordered dictionary, which can be easily converted to a pandas Series\n",
        "        # The keys in the dictionary will be used as the index (labels for the rows), with the values of the features\n",
        "        # as the values in the rows.\n",
        "                result = pandas.Series(extractor.execute(imageFilepath, maskFilepath, label))\n",
        "                featureVector = featureVector.append(result)\n",
        "            except Exception:\n",
        "                logger.error('FEATURE EXTRACTION FAILED:', exc_info=True)\n",
        "\n",
        "      # To add the calculated features for this case to our data frame, the series must have a name (which will be the\n",
        "      # name of the column.http://localhost:8888/notebooks/Documents/PyradiomicsResults/Template_cpu/pipeline_step3_test.ipynb#\n",
        "            featureVector.name = entry\n",
        "      # By specifying an 'outer' join, all calculated features are added to the data frame, including those not\n",
        "      # calculated for previous cases. This also ensures we don't end up with an empty frame, as for the first patient\n",
        "      # it is 'joined' with the empty data frame.\n",
        "            results = results.join(featureVector, how='outer')  # If feature extraction failed, results will be all NaN\n",
        "\n",
        "    logger.info('Extraction complete, writing CSV')\n",
        "    # .T transposes the data frame, so that each line will represent one patient, with the extracted features as columns\n",
        "    results.T.to_csv(outputFilepath, index=False, na_rep='NaN')\n",
        "    logger.info('CSV writing complete')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ48JqFZrJYv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7FP8-HVrJYv"
      },
      "outputs": [],
      "source": [
        "\n",
        "inputsheet = pandas.read_excel(\"/Users/mnlmd/Documents/Images/Image_info/allinfo_newinput_22.xlsx\")\n",
        "LRparams=pandas.read_excel(\"/Users/mnlmd/Documents/PyradiomicsResults/Key_results/20210115-010554_indfeat/Harmonised/Baseline/Results/LGR_ind_features_gs.xlsx\")\n",
        "PCAparams=pandas.read_excel(\"/Users/mnlmd/Documents/PyradiomicsResults/Key_results/20210127-145609_gridsearch/Feature_Selection/Harmonised/Baseline/Results/pcaHarm_BLclassifier_performance.xlsx\")\n",
        "faparams=pandas.read_excel(\"/Users/mnlmd/Documents/PyradiomicsResults/Key_results/20210127-145609_gridsearch/Harmonised/Baseline/Results/feat_3permetHarm_BL_MLperformance_feature_reduction.xlsx\")\n",
        "fbparams=pandas.read_excel(\"/Users/mnlmd/Documents/PyradiomicsResults/Key_results/20210127-145609_gridsearch/Feature_Selection/Baseline/Results/feat_sel_corrHarm_BL_MLperformance_feature_reduction.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGLDKZForJYv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgpKkTffrJYv"
      },
      "outputs": [],
      "source": [
        "outputFile= os.path.join(path, 'radiomics_features_pd_' +str(Date_folder)+'.csv')\n",
        "pyrad_output=pd.read_csv(outputFile)\n",
        "print(len(pyrad_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQZJr3TQrJYv"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# pyrad_output=pyrad_output.dropna(axis=0, how='any')\n",
        "pyrad_output=pyrad_output.reset_index()\n",
        "\n",
        "print(len(pyrad_output))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EfI510-rJYv"
      },
      "outputs": [],
      "source": [
        "pyrad_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AABy_tEhrJYv"
      },
      "outputs": [],
      "source": [
        "# inputsheet_suvx=pd.read_csv(\"/Users/mnlmd/Documents/Input/pyradinput20210927.csv\")\n",
        "# SUVx is the mean of the voxels that are equal or greater than x% of SUV max in the region of interest\n",
        "SUV50=[]\n",
        "SUV60=[]\n",
        "SUV70=[]\n",
        "SUV80=[]\n",
        "SUV90=[]\n",
        "for i, row in pyrad_output.iterrows():\n",
        "    try:\n",
        "        print(i)\n",
        "        PETname=row[\"Image\"]\n",
        "        fol=PETname.split(\"_\")[1]\n",
        "        fol2=PETname.split(\"_\")[0]\n",
        "        PETpath1='/Users/mnlmd/Documents/Input/'+fol+'/'+PETname\n",
        "        maskpath1=os.path.join('/Users/mnlmd/Documents/Outputs/3D/',row[\"Mask\"])\n",
        "        PETpath2='/Users/mnlmd/Documents/OneDriveUMCG/Input/'+fol2+'/'+PETname\n",
        "        maskpath2=os.path.join('/Volumes/TOSHIBA_EXT/Outputs/3D/',row[\"Mask\"])\n",
        "        PETpath3='/Users/mnlmd/Desktop/Gijs/Input/'+fol+'/'+PETname\n",
        "        maskpath3=os.path.join('/Users/mnlmd/Desktop/Gijs/Outputs/3D/',row[\"Mask\"])\n",
        "\n",
        "        PETpath=None\n",
        "        maskpath=None\n",
        "\n",
        "        print(maskpath1)\n",
        "        if os.path.isfile(PETpath1):\n",
        "\n",
        "            PETpath = PETpath1\n",
        "        elif os.path.isfile(PETpath2):\n",
        "\n",
        "\n",
        "            PETpath = PETpath2\n",
        "        elif os.path.isfile(PETpath3):\n",
        "            PETpath = PETpath3\n",
        "        else:\n",
        "            print('fail')\n",
        "\n",
        "\n",
        "        if os.path.isfile(maskpath1):\n",
        "            maskpath = maskpath1\n",
        "        elif os.path.isfile(maskpath2):\n",
        "                maskpath = maskpath2\n",
        "        elif os.path.isfile(maskpath3):\n",
        "                maskpath = maskpath3\n",
        "        else:\n",
        "            print('fail')\n",
        "\n",
        "\n",
        "        print(PETpath, maskpath)\n",
        "\n",
        "        imagePET = sitk.ReadImage(PETpath)\n",
        "        mask = sitk.ReadImage(maskpath)\n",
        "        PETarray=sitk.GetArrayFromImage(imagePET)\n",
        "\n",
        "        maskarray=sitk.GetArrayFromImage(mask)\n",
        "\n",
        "\n",
        "\n",
        "        try:\n",
        "    #     only values in whole aorta ROI\n",
        "            PETarray2=np.where(maskarray>0, PETarray,0)\n",
        "\n",
        "            PETarray_val = PETarray2[PETarray2 != 0]\n",
        "\n",
        "\n",
        "            try:\n",
        "                suvmax=PETarray_val.max()\n",
        "            except:\n",
        "                suvmax=0\n",
        "\n",
        "            suvmax50=0.5*suvmax\n",
        "            suvmax60=0.6*suvmax\n",
        "            suvmax70=0.7*suvmax\n",
        "            suvmax80=0.8*suvmax\n",
        "            suvmax90=0.9*suvmax\n",
        "\n",
        "            PETarray_50 = PETarray_val[PETarray_val >= suvmax50]\n",
        "            PETarray_60 = PETarray_val[PETarray_val >= suvmax60]\n",
        "            PETarray_70 = PETarray_val[PETarray_val >= suvmax70]\n",
        "            PETarray_80 = PETarray_val[PETarray_val >= suvmax80]\n",
        "            PETarray_90 = PETarray_val[PETarray_val >= suvmax90]\n",
        "\n",
        "\n",
        "            try:\n",
        "                suv50 = sum(PETarray_50) / len(PETarray_50)\n",
        "                suv60 = sum(PETarray_60) / len(PETarray_60)\n",
        "                suv70 = sum(PETarray_70) / len(PETarray_70)\n",
        "                suv80 = sum(PETarray_80) / len(PETarray_80)\n",
        "                suv90 = sum(PETarray_90) / len(PETarray_90)\n",
        "            except:\n",
        "                suv50 = 0\n",
        "                suv60 = 0\n",
        "                suv70 = 0\n",
        "                suv80 = 0\n",
        "                suv90 = 0\n",
        "        except:\n",
        "            suv50 = 0\n",
        "            suv60 = 0\n",
        "            suv70 = 0\n",
        "            suv80 = 0\n",
        "            suv90 = 0\n",
        "\n",
        "    except:\n",
        "\n",
        "        suv50 = 0\n",
        "        suv60 = 0\n",
        "        suv70 = 0\n",
        "        suv80 = 0\n",
        "        suv90 = 0\n",
        "\n",
        "    SUV50.append(suv50)\n",
        "    SUV60.append(suv60)\n",
        "    SUV70.append(suv70)\n",
        "    SUV80.append(suv80)\n",
        "    SUV90.append(suv90)\n",
        "    print(PETname, suv50, suv90)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "pyrad_output['SUV 50'] = SUV50\n",
        "pyrad_output['SUV 60'] = SUV60\n",
        "pyrad_output['SUV 70'] = SUV70\n",
        "pyrad_output['SUV 80'] = SUV80\n",
        "pyrad_output['SUV 90'] = SUV90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L3Q8Mp3rJYv"
      },
      "outputs": [],
      "source": [
        "pyrad_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkXrJ7-prJYw"
      },
      "outputs": [],
      "source": [
        "pyrad_output=pyrad_output.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OeXXF1arJYw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot6PM0-ErJYw"
      },
      "outputs": [],
      "source": [
        "Add_=pd.DataFrame( columns=inputsheet.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOgG6TVMrJYw"
      },
      "outputs": [],
      "source": [
        "inputsheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTs-DiRBrJYw"
      },
      "outputs": [],
      "source": [
        "row_= pd.Series([np.nan] * 8)\n",
        "print(row_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOQcSJ-prJYw"
      },
      "outputs": [],
      "source": [
        "for i, row in pyrad_output.iterrows():\n",
        "    image=row[\"Image\"]\n",
        "    x=0\n",
        "    for i, row in inputsheet.iterrows():\n",
        "        patient=row[\"Patient\"]\n",
        "        date=str(row[\"Date\"])\n",
        "\n",
        "\n",
        "        if patient in image:\n",
        "            if date in image or date=='dateunknown':\n",
        "                    Add_=Add_.append(row,ignore_index=True)\n",
        "                    x=1\n",
        "                    print(len(Add_))\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "\n",
        "    if x==0:\n",
        "        row_= pd.Series([np.nan] * len(row))\n",
        "\n",
        "        Add_=Add_.append(row_,ignore_index=True)\n",
        "\n",
        "print(len(Add_))\n",
        "# if len(Add_) != len(pyrad_output):\n",
        "#     sys.exit('Adding patient info failed - lengths not equal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPqk0twyrJYw"
      },
      "outputs": [],
      "source": [
        "Add_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8bGugUTrJYw"
      },
      "outputs": [],
      "source": [
        "Add_1=Add_.loc[:,'Patient':'Scanner']\n",
        "# Add_2=Add_.loc[:,'SUV 50':'Grade Ground Truth']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FUvmSlfrJYw"
      },
      "outputs": [],
      "source": [
        "path_harm=os.path.join(path, \"Harmonised\")\n",
        "path_org=os.path.join(path, \"Original\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmFqg8yArJYw"
      },
      "outputs": [],
      "source": [
        "Add_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af7yGSczrJYw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz0HlQ5qrJYw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4Fl7Ht1rJYw"
      },
      "outputs": [],
      "source": [
        "pyrad_output=pd.concat([pyrad_output,Add_1],axis=1)\n",
        "# pyrad_output=pd.concat([pyrad_output,Add_1],axis=1)\n",
        "print(len(pyrad_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAVyuk6KrJYw"
      },
      "outputs": [],
      "source": [
        "# pyrad_output[\"Patient.1\"]\n",
        "pyrad_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdq5ZVwJrJYw"
      },
      "outputs": [],
      "source": [
        "# np.where(pyrad_output[\"Patient.1\"]==\"LVV42_\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnSoxopWrJYw"
      },
      "outputs": [],
      "source": [
        "# pyrad_output.at[70,\"Diagnosis\"]=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCCKe4SMrJYw"
      },
      "outputs": [],
      "source": [
        "df_data= pd.DataFrame(columns= [\"Param\", \"Value\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sA2oJKxrJYx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pxQjWdrrJYx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_FUtslRrJYx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtUZqRX0rJYx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gjo-2XorJYx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlrq-0JTrJYx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJjm7Z1crJYx"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Grade=[]\n",
        "# for i, row in pyrad_output.iterrows():\n",
        "\n",
        "\n",
        "#     liverSUVmean=row[\"Liver SUVmean\"]\n",
        "\n",
        "#     try:\n",
        "#         liverSUVmean=float(liverSUVmean)\n",
        "\n",
        "#     except:\n",
        "#         liverSUVmean = liverSUVmean.replace('--', '0')\n",
        "#         liverSUVmean=float(liverSUVmean)\n",
        "\n",
        "#     Suv50=float(row[\"original_firstorder_90Percentile\"])\n",
        "#     bpsuvmean=float(row[\"Blood Pool SUV Mean\"])\n",
        "\n",
        "#     if Suv50<=bpsuvmean:\n",
        "#         grade=0\n",
        "\n",
        "#     elif Suv50<(0.95*liverSUVmean) and Suv50>bpsuvmean:\n",
        "#         grade=1\n",
        "\n",
        "#     elif Suv50>=(0.95*liverSUVmean) and Suv50<=(1.05*liverSUVmean):\n",
        "#         grade=2\n",
        "\n",
        "#     elif Suv50>(1.05*liverSUVmean):\n",
        "#         grade=3\n",
        "\n",
        "\n",
        "\n",
        "#     Grade.append(grade)\n",
        "\n",
        "# print(len(Grade),len(pyrad_output))\n",
        "# if len(Grade) != len(pyrad_output):\n",
        "#     sys.exit('Grading failed - lengths not equal')\n",
        "\n",
        "\n",
        "# pyrad_output['Grade Manual'] = Grade\n",
        "\n",
        "# change to grade only method soon\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSE5w8fArJYx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOlkOi5rrJYx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-51_VMbErJYx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUXHUMXKrJYx"
      },
      "outputs": [],
      "source": [
        "pyrad_output.rename(columns = {'Patient.1':'Patient'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9FJ8OerrJYx"
      },
      "outputs": [],
      "source": [
        "pyrad_output.to_excel(os.path.join(path,\"pyrad_output_complete.xlsx\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLKwrnvtrJYx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_-si2uBrJYx"
      },
      "outputs": [],
      "source": [
        "# pyrad_output=pd.read_excel(\"/Users/mnlmd/Documents/PyradiomicsResults/20221117/20221117-161006/pyrad_output_complete.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgFBUc41rJYx"
      },
      "outputs": [],
      "source": [
        "pyrad_output=pd.read_excel(\"/Users/mnlmd/Documents/PyradiomicsResults/20221222/20221222-213019/pyrad_output_complete_2.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjephYwprJYy"
      },
      "outputs": [],
      "source": [
        "# pyrad_output=pd.read_excel(os.path.join(path,\"pyrad_output_complete.xlsx\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3p4WPsarJYy"
      },
      "outputs": [],
      "source": [
        "pyrad_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkc7PAcErJYy"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu5uPmFrrJYy"
      },
      "outputs": [],
      "source": [
        "\n",
        "Harm=pyrad_output\n",
        "\n",
        "\n",
        "Harm_ = Harm.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "print(Harm_.isnull().values.any())\n",
        "print(Harm.shape)\n",
        "print(Harm_.shape)\n",
        "\n",
        "\n",
        "# std_scaler = StandardScaler()\n",
        "\n",
        "# Harm_2= std_scaler.fit_transform(Harm_.to_numpy())\n",
        "# Harm_2= pd.DataFrame(Harm_2,columns=Harm_.columns)\n",
        "# Harm_=Harm_2\n",
        "\n",
        "# print(\"Scaled Dataset Using StandardScaler\")\n",
        "# print(Harm_.head())\n",
        "\n",
        "\n",
        "Harm_diags = Harm.loc[:,\"Image\":\"diagnostics_Versions_SimpleITK\"]\n",
        "Harm_.set_index(Harm['Patient'])\n",
        "Harm_app= Harm.loc[:,\"Patient\"  :]\n",
        "print(Harm_app.shape)\n",
        "Harm_app.set_index(Harm[\"Patient\"])\n",
        "batch_col = 'Scanner'\n",
        "\n",
        "# data=np.transpose(Harm_)\n",
        "\n",
        "# covars=pd.DataFrame(Harm['Patient'])\n",
        "\n",
        "data_combat = neuroCombat(data=Harm_,\n",
        "                          covars=Harm_app,\n",
        "                          batch_col=batch_col)\n",
        "\n",
        "print((data_combat))\n",
        "Harmonised = pd.DataFrame(data_combat)\n",
        "print(Harmonised)\n",
        "# Harmonised=np.transpose(HarmonisedT)\n",
        "\n",
        "Harmonised=Harmonised.set_index(Harm['Patient'])\n",
        "Harm_app=Harm_app.set_index(Harm[\"Patient\"])\n",
        "Harm_diags=Harm_diags.set_index(Harm[\"Patient\"])\n",
        "Harmonised.columns = Harm_.columns\n",
        "\n",
        "Harmonised=pd.concat([Harmonised, Harm_app], axis=1)\n",
        "Harmonised=pd.concat([Harm_diags, Harmonised], axis=1)\n",
        "Harmonised.to_excel(os.path.join(path_harm,\"Harmonised.xlsx\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYPGjRhXrJYy"
      },
      "outputs": [],
      "source": [
        "# from pycombat import Combat\n",
        "# Harm=pyrad_output\n",
        "\n",
        "\n",
        "# Harm_ = Harm.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "# # print(Harm_.isnull().values.any())\n",
        "# print(Harm.shape)\n",
        "# print(Harm_.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcTzpeZrrJYy"
      },
      "outputs": [],
      "source": [
        "# Harm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTYumUR1rJYy"
      },
      "outputs": [],
      "source": [
        "# Harm_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Akg3DparrJYy"
      },
      "outputs": [],
      "source": [
        "# Harm['Scanner']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7QDx-jRrJYy"
      },
      "outputs": [],
      "source": [
        "# combat = Combat()\n",
        "# # df.reset_index()\n",
        "# Harm_diags = Harm.loc[:,\"Image\":\"diagnostics_Versions_SimpleITK\"]\n",
        "# Harm_=Harm_.set_index(Harm['Patient'])\n",
        "# Harm=Harm.set_index(Harm['Patient'])\n",
        "# Harm_app= Harm.loc[:,\"Patient\"  :]\n",
        "# # print(Harm_app.shape)\n",
        "# Harm_app.set_index(Harm[\"Patient\"])\n",
        "\n",
        "\n",
        "# data=np.transpose(Harm_)\n",
        "\n",
        "# # covars=pd.DataFrame(Harm['Patient'])\n",
        "\n",
        "# b=Harm['Scanner']\n",
        "\n",
        "# print(b)\n",
        "# print(data.shape, Harm_.shape)\n",
        "# print(Harm['Scanner'].shape)\n",
        "# # combat.fit(Y=Harm_, b=b)\n",
        "# Harmonised = combat.fit_transform(Y=Harm_, b=b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk4T8zCfrJYy"
      },
      "outputs": [],
      "source": [
        "# data_combat = neuroCombat(dat=data,\n",
        "#                           covars=Harm_app,\n",
        "# #                           batch_col=batch_col)\n",
        "\n",
        "\n",
        "# # HarmonisedT = pd.DataFrame(data=data_combat)\n",
        "# # print(HarmonisedT)\n",
        "\n",
        "\n",
        "# Harmonised=Harmonised.set_index(Harm['Patient'])\n",
        "# Harm_app=Harm_app.set_index(Harm[\"Patient\"])\n",
        "# Harm_diags=Harm_diags.set_index(Harm[\"Patient\"])\n",
        "# Harmonised.columns = Harm_.columns\n",
        "\n",
        "# Harmonised=pd.concat([Harmonised, Harm_app], axis=1)\n",
        "# Harmonised=pd.concat([Harm_diags, Harmonised], axis=1)\n",
        "# Harmonised.to_excel(os.path.join(path_harm,\"Harmonised.xlsx\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5f1uks4rJYy"
      },
      "outputs": [],
      "source": [
        "# Harmonised=pyrad_output2.loc[:,\"Image\":\"Scanner\"]\n",
        "pyrad_output=pyrad_output.loc[:,\"Image\":\"Scanner\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crMhknVgrJYy"
      },
      "outputs": [],
      "source": [
        "# refining full set, org and harm will be passed through\n",
        "dataframes=[Harmonised, pyrad_output]\n",
        "\n",
        "Harmonised.name = 'Harmonised'\n",
        "\n",
        "pyrad_output.name = 'pyrad_output'\n",
        "\n",
        "\n",
        "for df in dataframes:\n",
        "\n",
        "    df['Diagnosis'] = df['Diagnosis'].astype(float)\n",
        "    df['Control Type'] = df['Control Type'].astype(float)\n",
        "    df['Category'] = df['Category'].astype(float)\n",
        "\n",
        "\n",
        "    df['Dataset'] = df['Dataset'].astype(float)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtjNDEtarJYy"
      },
      "outputs": [],
      "source": [
        "radfeat= pyrad_output.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "Feature= radfeat.columns.values\n",
        "\n",
        "\n",
        "\n",
        "Feature = [f.replace('original_', '') for f in Feature]\n",
        "Feature = [f.replace('_', ' ') for f in Feature]\n",
        "Feature = [f.replace('gldm', 'GLDM') for f in Feature]\n",
        "Feature = [f.replace('glrlm', 'GLRLM') for f in Feature]\n",
        "Feature = [f.replace('glszm', 'GLSZM') for f in Feature]\n",
        "Feature = [f.replace('glcm', 'GLCM') for f in Feature]\n",
        "Feature = [f.replace('ngtdm', 'NGTDM') for f in Feature]\n",
        "x=pd.Series(Feature)\n",
        "print(Feature)\n",
        "print(type(x))\n",
        "f = open(os.path.join(path,\"features.txt\"), \"a\")\n",
        "print(x.to_latex(index=False), file=f)\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oImQ8FzirJYz"
      },
      "outputs": [],
      "source": [
        "for df in dataframes:\n",
        "\n",
        "    a=[float(3.0),float(2.0)]\n",
        "    b=[float(0.0),float(1.0),float(2.0)]\n",
        "\n",
        "\n",
        "    full=df\n",
        "    BL = full\n",
        "\n",
        "    GCA = BL[BL['Category'].isin(b)]\n",
        "\n",
        "    if \"Harm\" in df.name:\n",
        "        outputpath=path_harm\n",
        "    if \"_\" in df.name:\n",
        "        outputpath=path_org\n",
        "\n",
        "\n",
        "    full.to_excel(os.path.join(outputpath,\"pyrad_full.xlsx\"))\n",
        "    BL.to_excel(os.path.join(outputpath,\"Baseline\",\"pyrad_BL.xlsx\"))\n",
        "    GCA.to_excel(os.path.join(outputpath,\"GCA\",\"pyrad_GCA.xlsx\"))\n",
        "    print(df.name)\n",
        "    if \"Harm\" in df.name:\n",
        "        Harm_BL=BL\n",
        "        Harm_GCA=GCA\n",
        "    if \"_\" in df.name:\n",
        "        Org_BL=BL\n",
        "        Org_GCA=GCA\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHKJF8SVrJYz"
      },
      "outputs": [],
      "source": [
        "print(np.shape(Harmonised))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AX8zfMYrJYz"
      },
      "outputs": [],
      "source": [
        "Org_GCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i98ood8srJYz"
      },
      "outputs": [],
      "source": [
        "Org_BL=Org_BL.set_index(Org_BL[\"Patient\"])\n",
        "Org_GCA=Org_GCA.set_index(Org_GCA[\"Patient\"])\n",
        "\n",
        "dfs=[Harm_GCA,Org_GCA]\n",
        "\n",
        "# dfs=[Harm_GCA,Harm_BL,Org_BL,Org_GCA]\n",
        "Harm_BL.name=\"Harm_BL\"\n",
        "Harm_GCA.name=\"Harm_GCA\"\n",
        "Org_BL.name=\"Org_BL\"\n",
        "Org_GCA.name=\"Org_GCA\"\n",
        "dfs_harm=[Harm_BL, Harm_GCA]\n",
        "dfs_org=[Org_BL, Org_GCA]\n",
        "\n",
        "plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "plt.rc('legend', fontsize=10)    # legend fontsize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCkysrqDrJYz"
      },
      "outputs": [],
      "source": [
        "# def popdis(df_bl,path_type):\n",
        "\n",
        "#     plt.rc('legend', fontsize=18)\n",
        "#     y_BL=df_bl['Subtypes Broad'].astype(str)\n",
        "#     x_BL=df_bl['Diagnosis'].astype(str)\n",
        "#     count_GCA=y_BL.value_counts()\n",
        "#     count_LVV=x_BL.value_counts()\n",
        "\n",
        "#     LVV=count_LVV.loc[\"1.0\"]\n",
        "#     gca=count_GCA.loc[\"1.0\"]\n",
        "#     control_gca=count_GCA.loc[\"0.0\"]\n",
        "#     control_lvv=count_LVV.loc[\"0.0\"]\n",
        "#     TAK=count_GCA.loc[\"2.0\"]\n",
        "#     misc=count_GCA.loc[\"4.0\"]\n",
        "#     unsp=count_GCA.loc[\"3.0\"]\n",
        "\n",
        "#     print(\" LVV:\" +str(LVV),\" GCA:\" +str(gca),\" Control gca:\" +str(control_gca),\" Control lvv:\" +str(control_lvv),\" TAK:\" +str(TAK),\" Misc:\" +str(misc),\" unsp:\" +str(misc))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     labels = 'GCA', 'TAK', 'Miscellaneous', 'Unspecified LVV', 'Control'\n",
        "#     sizes = [ int(gca), int(TAK), int(misc), int(unsp), int(control_lvv)]\n",
        "#     x = np.char.array([ 'GCA', 'TAK', 'Miscellaneous', 'Unspecified LVV', 'Control'])\n",
        "#     y = np.array(sizes)\n",
        "#     colors=['indigo','mediumpurple', 'darkviolet','thistle','slateblue',]  # 'indigo', 'darkviolet','medium purple','darkmagenta','slateblue','thistle'\n",
        "\n",
        "#     porcent = 100.*y/y.sum()\n",
        "\n",
        "#     patches, texts = plt.pie(y, colors=colors, startangle=90, radius=2)\n",
        "#     labels = ['{0} - {1:1.2f} %  - {2}'.format(i,j,k) for i,j,k in zip(x, porcent,y)]\n",
        "\n",
        "#     sort_legend = True\n",
        "#     if sort_legend:\n",
        "#         patches, labels, dummy =  zip(*sorted(zip(patches, labels, y),\n",
        "#                                               key=lambda x: x[2],\n",
        "#                                               reverse=True))\n",
        "\n",
        "#     plt.legend(patches,  labels, loc = 3, bbox_to_anchor=(2, 0))\n",
        "#     fname=os.path.join(path_type,\"Cat_Pop_Dis.jpg\")\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig(fname, bbox_inches = \"tight\", dpi=300,quality=95)\n",
        "#     plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "#     sizes = [ int(LVV), int(control_lvv)]\n",
        "#     x = np.char.array([ 'LVV', 'Control'])\n",
        "#     y = np.array(sizes)\n",
        "#     colors=['indigo','thistle',]  # 'indigo', 'darkviolet','medium purple','darkmagenta','slateblue','thistle'\n",
        "\n",
        "#     porcent = 100.*y/y.sum()\n",
        "\n",
        "#     patches, texts = plt.pie(y, colors=colors, startangle=90, radius=2)\n",
        "#     labels = ['{0} - {1:1.2f} %  - {2}'.format(i,j,k) for i,j,k in zip(x, porcent,y)]\n",
        "\n",
        "#     sort_legend = True\n",
        "#     if sort_legend:\n",
        "#         patches, labels, dummy =  zip(*sorted(zip(patches, labels, y),\n",
        "#                                               key=lambda x: x[2],\n",
        "#                                               reverse=True))\n",
        "\n",
        "#     plt.legend(patches,  labels, loc = 2, bbox_to_anchor=(2, 0))\n",
        "\n",
        "#     fname=os.path.join(path_type,\"Baseline\",\"Figures\",\"BL_Pop_Dis.jpg\")\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig(fname, bbox_inches = \"tight\", dpi=300,quality=95)\n",
        "#     plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     sizes = [ int(gca), int(control_lvv)]\n",
        "#     x = np.char.array([ 'GCA', 'Control'])\n",
        "#     y = np.array(sizes)\n",
        "#     colors=['indigo','thistle',]  # 'indigo', 'darkviolet','medium purple','darkmagenta','slateblue','thistle'\n",
        "\n",
        "#     porcent = 100.*y/y.sum()\n",
        "\n",
        "#     patches, texts = plt.pie(y, colors=colors, startangle=90, radius=2)\n",
        "#     labels = ['{0} - {1:1.2f} %  - {2}'.format(i,j,k) for i,j,k in zip(x, porcent,y)]\n",
        "\n",
        "#     sort_legend = True\n",
        "#     if sort_legend:\n",
        "#         patches, labels, dummy =  zip(*sorted(zip(patches, labels, y),\n",
        "#                                               key=lambda x: x[2],\n",
        "#                                               reverse=True))\n",
        "\n",
        "#     plt.legend(patches,  labels, loc = 2, bbox_to_anchor=(2, 0))\n",
        "\n",
        "#     fname=os.path.join(path_type,\"GCA\", \"Figures\",\"GCA_Pop_Dis.jpg\")\n",
        "#     plt.tight_layout()\n",
        "#     plt.savefig(fname, bbox_inches = \"tight\", dpi=300,quality=95)\n",
        "#     plt.clf()\n",
        "#     return(LVV, gca, control_lvv, TAK, misc, unsp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjAYFB4LrJYz"
      },
      "outputs": [],
      "source": [
        "# popdis(Harm_BL,path_harm)\n",
        "\n",
        "# popdis(Org_BL,path_org)\n",
        "\n",
        "# plt.rc('legend', fontsize=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhx56sZ9rJYz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZIQEmnerJYz"
      },
      "outputs": [],
      "source": [
        "\n",
        "# for dataframe in dfs:\n",
        "#     if \"Harm\" in dataframe.name:\n",
        "\n",
        "#         path_type = path_harm\n",
        "#     if \"Org\" in dataframe.name:\n",
        "#         path_type = path_org\n",
        "#     if \"BL\" in dataframe.name:\n",
        "\n",
        "#         folder = \"Baseline\"\n",
        "#     if \"GCA\" in dataframe.name:\n",
        "#         folder = \"GCA\"\n",
        "#     x_grades=dataframe['Grade Manual'].astype(str)\n",
        "#     count_Grades=x_grades.value_counts()\n",
        "\n",
        "#     print(count_Grades)\n",
        "\n",
        "\n",
        "\n",
        "#     df_grad= pd.DataFrame(columns= [\"Grade\", \"No. of Patients with Grade\"])\n",
        "#     try:\n",
        "#         df_grad=df_grad.append ({\"Grade\":\"0\", \"No. of Patients with Grade\":count_Grades[\"0\"] }, ignore_index=True)\n",
        "#     except:\n",
        "#         df_grad=df_grad.append ({\"Grade\":\"0\", \"No. of Patients with Grade\": \"0\" }, ignore_index=True)\n",
        "\n",
        "\n",
        "#     df_grad=df_grad.append ({\"Grade\":\"1\", \"No. of Patients with Grade\":count_Grades[\"1\"] }, ignore_index=True)\n",
        "#     df_grad=df_grad.append ({\"Grade\":\"2\", \"No. of Patients with Grade\":count_Grades[\"2\"] }, ignore_index=True)\n",
        "#     df_grad=df_grad.append ({\"Grade\":\"3\", \"No. of Patients with Grade\":count_Grades[\"3\"] }, ignore_index=True)\n",
        "\n",
        "#     df_grad.to_excel(os.path.join(path_type,folder,\"Results\",\"grades.xlsx\"))\n",
        "#     f = open(os.path.join(path_type,folder,\"Results\",\"grades.txt\"), \"a\")\n",
        "#     print(df_grad.to_latex(), file=f)\n",
        "#     f.close()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pPS7zWgrJYz"
      },
      "outputs": [],
      "source": [
        "df_delong= pd.DataFrame(columns= [\"Label\", \"ML Type\", \"Dataset\",\"Ground Truth\", \"Prediction\",\"AUC\",\"CI\"])\n",
        "# df_delong=df_delong.append({\"Label\", \"ML Type\", \"Dataset\",\"Ground Truth\", \"Prediction\"},ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRRiLa7WrJYz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1dEgGi6rJYz"
      },
      "outputs": [],
      "source": [
        "df_delong\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Y-G2c8OrJYz"
      },
      "outputs": [],
      "source": [
        "def CIauc(y_true,y_pred):\n",
        "    alpha = .95\n",
        "\n",
        "    auc, auc_cov = delong.delong_roc_variance(\n",
        "        y_true,\n",
        "        y_pred)\n",
        "\n",
        "    auc_std = np.sqrt(auc_cov)\n",
        "    lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
        "\n",
        "    ci = stats.norm.ppf(\n",
        "        lower_upper_q,\n",
        "        loc=auc,\n",
        "        scale=auc_std)\n",
        "    print(lower_upper_q,auc,auc_std)\n",
        "\n",
        "    ci[ci > 1] = 1\n",
        "\n",
        "    print('AUC:', auc)\n",
        "    print('AUC COV:', auc_cov)\n",
        "    print('95% AUC CI:', ci)\n",
        "    print(\"inside def:\", auc, ci)\n",
        "    return(auc, ci)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZJB-cQFrJYz"
      },
      "outputs": [],
      "source": [
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91BKMVuzrJY0"
      },
      "outputs": [],
      "source": [
        "def PrinCA(dataframe, ML_type,  folder, path_type,params):\n",
        "    global df_delong\n",
        "    a=list(dataframe.columns.values)\n",
        "\n",
        "    plt.style.use('seaborn')\n",
        "    X_ext= dataframe.loc[dataframe['Dataset'] == float(2.0)]\n",
        "    X_cases= dataframe\n",
        "\n",
        "    Xi_test= dataframe.loc[dataframe['Dataset'] == float(3.0)]\n",
        "    Xi_train= dataframe.loc[dataframe['Dataset'] == float(1.0)]\n",
        "#     print(X_int.shape)\n",
        "    yi_train=Xi_train['Diagnosis']\n",
        "    yi_test=Xi_test['Diagnosis']\n",
        "    y_ext=X_ext['Diagnosis']\n",
        "    y_cases=X_cases['Diagnosis']\n",
        "\n",
        "    y_cases_app=X_cases.loc[:,'Patient':'Dataset']\n",
        "\n",
        "\n",
        "    Xi_train_pca=Xi_train.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "#     print(Xi_train_pca)\n",
        "    Xi_train_pca.reset_index()\n",
        "#     yi_train=dataframe['Diagnosis']  # Labels\n",
        "#     X=X.set_index(dataframe[\"Patient\"])\n",
        "#     print(X)\n",
        "    # y.set_index(dataframe[\"Patient\"])\n",
        "#     print(Xi_train_pca)\n",
        "    Xi_train_pca=StandardScaler().fit_transform(Xi_train_pca)\n",
        "\n",
        "#     print(Xi_train_pca)\n",
        "\n",
        "    pca = PCA(n_components=0.9, svd_solver='full', whiten=True)\n",
        "    principalComponents = pca.fit_transform(Xi_train_pca)\n",
        "#     print(principalComponents.shape)\n",
        "\n",
        "    vr=pca.explained_variance_ratio_\n",
        "\n",
        "    svr=pca.explained_variance_ratio_.cumsum()\n",
        "\n",
        "    v=pca.explained_variance_\n",
        "\n",
        "    tv=pca.explained_variance_ratio_.sum()\n",
        "\n",
        "    num_comp=pca.n_components_\n",
        "#     print(vr, svr,v,tv,num_comp)\n",
        "\n",
        "#     print((Xi_test.loc[:,\"original_shape_Elongation\":\"SUV 90\"]).shape)\n",
        "    Xi_test_pca=pca.transform(Xi_test.loc[:,\"original_shape_Elongation\":\"SUV 90\"])\n",
        "    X_ext_pca=pca.transform(X_ext.loc[:,\"original_shape_Elongation\":\"SUV 90\"])\n",
        "    X_cases_pca=pca.transform(X_cases.loc[:,\"original_shape_Elongation\":\"SUV 90\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    principalDf_train = pd.DataFrame(data = principalComponents\n",
        "                 )\n",
        "    principalDf_itest = pd.DataFrame(data = Xi_test_pca\n",
        "             )\n",
        "    principalDf_ext = pd.DataFrame(data = X_ext_pca\n",
        "             )\n",
        "    principalDf_cases = pd.DataFrame(data = X_cases_pca)\n",
        "    principalDf_train=principalDf_train.set_index(Xi_train[\"Patient\"])\n",
        "\n",
        "    principalDf_itest=principalDf_itest.set_index(Xi_test[\"Patient\"])\n",
        "    principalDf_ext=principalDf_ext.set_index(X_ext[\"Patient\"])\n",
        "    principalDf_cases=principalDf_cases.set_index(X_cases[\"Patient\"])\n",
        "\n",
        "\n",
        "#     yi_train=pd.DataFrame(yi_train)\n",
        "\n",
        "#     yi_test=pd.DataFrame(yi_test)\n",
        "#     y_ext=pd.DataFrame(y_ext)\n",
        "\n",
        "\n",
        "#     principalDf_train=principalDf_train.reset_index(drop=True)\n",
        "\n",
        "#     principalDf_itest=principalDf_itest.reset_index(drop=True)\n",
        "#     principalDf_ext=principalDf_ext.reset_index(drop=True)\n",
        "\n",
        "\n",
        "#     yi_train=yi_train.reset_index(drop=True)\n",
        "\n",
        "#     yi_test=yi_test.reset_index(drop=True)\n",
        "#     y_ext=y_ext.reset_index(drop=True)\n",
        "#     print(principalDf_train.shape, yi_train.shape)\n",
        "    finalDf_train = pd.concat([principalDf_train, yi_train], axis = 1)\n",
        "    finalDf_test = pd.concat([principalDf_itest, yi_test], axis = 1)\n",
        "    finalDf_val = pd.concat([principalDf_ext, y_ext], axis = 1)\n",
        "    finalDf_cases = pd.concat([principalDf_cases, y_cases], axis = 1)\n",
        "    print(type(principalDf_cases),type(y_cases))\n",
        "\n",
        "\n",
        "    principalDf_train=principalDf_train.to_numpy()\n",
        "\n",
        "    principalDf_itest=principalDf_itest.to_numpy()\n",
        "    principalDf_ext=principalDf_ext.to_numpy()\n",
        "    principalDf_cases=principalDf_cases.to_numpy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     sliced = dataframe.drop(['Diagnosis'], axis=1)\n",
        "#     a=list(sliced.columns.values)\n",
        "\n",
        "#     X=sliced.to_numpy()\n",
        "\n",
        "#     y=dataframe['Diagnosis']  # Labels\n",
        "\n",
        "\n",
        "\n",
        "#     for i,row in params.iterrows():\n",
        "#         ML=str(row[\"ML Type\"])\n",
        "\n",
        "#         if ML_type==ML:\n",
        "# #                 try:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#                 print(ML_type, ML)\n",
        "#                 prms=row[\"Params\"]\n",
        "\n",
        "# #                     prms=prms.replace(\"'\",\" \" \" )\n",
        "#                 prms=ast.literal_eval(prms)\n",
        "# #                     prms=prms.replace(\":\",\"=\")\n",
        "#                 print(prms)\n",
        "#                 print(\"type prms\" + str(type(prms)))\n",
        "\n",
        "    if ML_type == \"rf\":\n",
        "        cl=RandomForestClassifier()\n",
        "        prms=[{'n_estimators': [10, 2000],\n",
        "                'bootstrap': [True, False],\n",
        "                 'max_depth': [10,   1000],\n",
        "                 'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "               'random_state':[1],\n",
        "                 'min_samples_leaf': [1, 10],\n",
        "                 'min_samples_split': [2, 10]}]\n",
        "    if ML_type == \"lgr\":\n",
        "        cl=LogisticRegression()\n",
        "        prms=[{'max_iter': [10, 10000],\n",
        "        'C': [1.0,4.0],\n",
        "         'dual': [False],\n",
        "         'solver': [\"liblinear\"],\n",
        "               'random_state':[1],\n",
        "               \"penalty\":[\"l2\",\"l1\",None],\n",
        "               'tol': [1e-7,1e-1],\n",
        "               'fit_intercept': [True, False],\n",
        "               'intercept_scaling': [1,5],\n",
        "\n",
        "         'penalty': ['l1', 'l2']}]\n",
        "    if ML_type == \"svm\":\n",
        "        cl=svm.SVC(probability=True)\n",
        "        prms=[{'C': [1,10],\n",
        "                'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "               'random_state':[1],\n",
        "                 'gamma': ['scale', 'auto']}]\n",
        "    if ML_type == \"lr\":\n",
        "        cl=linear_model.LinearRegression()\n",
        "        prms=[{'fit_intercept': [True, False],\n",
        "               'random_state':[1],\n",
        "                'normalize': [True, False]}]\n",
        "    if ML_type == \"ridge\":\n",
        "        cl=linear_model.RidgeClassifierCV()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'normalize': [True, False],\n",
        "               'random_state':[1],\n",
        "                 'scoring': ['accuracy', 'roc_auc'],\n",
        "                 'cv': [1,5]}]\n",
        "    if ML_type == \"lasso\":\n",
        "        cl=linear_model.Lasso()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'normalize': [True, False],\n",
        "                 'alpha': [0.1,2.0],\n",
        "               'random_state':[1],\n",
        "                 'max_iter': [5, 1000],\n",
        "                 'selection': ['cyclic', 'random']}]\n",
        "    if ML_type == \"el_net\":\n",
        "        cl=linear_model.ElasticNetCV()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "            'normalize': [True, False],\n",
        "             'alpha': [0.0, 1.0],\n",
        "               'tol': [1e-5,1e-3],\n",
        "             'max_iter': [5,2000],\n",
        "             'selection': ['cyclic', 'random'],\n",
        "            'l1_ratio': [0.0,  1.0],\n",
        "               'random_state':[1],\n",
        "            'positive': [True, False]}]\n",
        "    if ML_type == \"lars\":\n",
        "        cl=linear_model.LassoLars()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'normalize': [True, False],\n",
        "               'random_state':[1],\n",
        "                 'alpha': [0.0,2.0],\n",
        "                 'max_iter': [ 5, 1000],\n",
        "\n",
        "                }]\n",
        "    if ML_type == \"omp\":\n",
        "        cl=linear_model.OrthogonalMatchingPursuit()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "               'random_state':[1],\n",
        "                'normalize': [True, False]}]\n",
        "    if ML_type == \"bayrid\":\n",
        "        cl=linear_model.BayesianRidge()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'normalize': [True, False],\n",
        "               'random_state':[1],\n",
        "                 'alpha_1': [1e-7,1e-5],\n",
        "                 'alpha_2': [1e-7,1e-5],\n",
        "                 'lambda_1': [1e-7,1e-5],\n",
        "              'lambda_2':[1e-7,1e-5]}]\n",
        "    if ML_type == \"sgd\":\n",
        "        cl=linear_model.SGDClassifier()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'average': [True, False],\n",
        "                 'loss': ['hinge','log'],\n",
        "               'random_state':[1],\n",
        "                 'max_iter': [ 5, 1000],\n",
        "                 'alpha': [0.001,0.1]}]\n",
        "    if ML_type == \"perc\":\n",
        "        cl=linear_model.Perceptron()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'penalty': ['l2', 'l1','elasticnet','None'],\n",
        "                 'alpha': [0.01,0.1],\n",
        "               'random_state':[1],\n",
        "                 'max_iter': [ 5, 1000]}]\n",
        "    if ML_type == \"pasagr\":\n",
        "        cl=linear_model.PassiveAggressiveClassifier()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'C': [0.0,2.0],\n",
        "                 'max_iter': [5, 2000],\n",
        "               'random_state':[1],\n",
        "                 'average': [True, False]}]\n",
        "    if ML_type == \"nnet\":\n",
        "        cl=MLPClassifier()\n",
        "        prms=[{  'alpha': [0.00001,0.1],\n",
        "#                'random_state':[1],\n",
        "#                  'hidden_layer_sizes': [(5,), (10,), (100,), (500,)],\n",
        "                 'max_iter': [100,  1000]}]\n",
        "    if ML_type == \"kneigh\":\n",
        "        cl=KNeighborsClassifier()\n",
        "        prms=[{ 'n_neighbors': [2,5],\n",
        "                'weights': ['uniform', 'distance'],\n",
        "\n",
        "                 'algorithm': ['auto','kd_tree', 'brute','ball_tree'],\n",
        "                 'leaf_size': [10,50]}]\n",
        "    if ML_type == \"dt\":\n",
        "        cl=tree.DecisionTreeClassifier()\n",
        "        prms=[{  'criterion': [\"gini\", \"entropy\"],\n",
        "                 'splitter': ['best', 'random'],\n",
        "\n",
        "                 'max_leaf_nodes': [2,100],\n",
        "               'random_state':[1],\n",
        "               'min_impurity_decrease': [0.0, 0.5],\n",
        "\n",
        "\n",
        "                 'ccp_alpha': [0.0,  1.0],\n",
        "               'max_depth': [5,    1000],\n",
        "                 'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "                 'min_samples_leaf': [2,  50],\n",
        "                 'min_samples_split': [2,10]}]\n",
        "    if ML_type == \"gpc\":\n",
        "        kernel = 1.0 * RBF(1.0)\n",
        "        cl = GaussianProcessClassifier(kernel=kernel)\n",
        "        prms=[{  'max_iter_predict': [10, 2000], 'random_state':[1]}]\n",
        "    if ML_type == \"nearcent\":\n",
        "        cl=NearestCentroid()\n",
        "        prms=[]\n",
        "\n",
        "\n",
        "    opt=BayesSearchCV(cl,prms, n_iter=64, cv=5)\n",
        "    opt=opt.fit(principalDf_train,yi_train)\n",
        "\n",
        "\n",
        "    print(\"optimised\")\n",
        "    print(ML_type)\n",
        "    print(\"params best score\")\n",
        "    print(opt.best_score_)\n",
        "    prms_best= opt.best_params_\n",
        "    print(prms_best)\n",
        "\n",
        "\n",
        "#     pkl_filename = str(ML_type)+\"_\" +str(label)+\"_\"+ str(dataframe.name)+\"_model.pkl\"\n",
        "#     pkl_save=os.path.join(path_type,folder,pkl_filename)\n",
        "#     with open(pkl_save, 'wb') as file:\n",
        "#         pickle.dump(clf, file)\n",
        "\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5)\n",
        "\n",
        "    classifier=cl\n",
        "    classifier=classifier.set_params(**prms_best)\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "\n",
        "\n",
        "    accs=[]\n",
        "    rcs=[]\n",
        "\n",
        "    mean_fpr = np.linspace(0, 1, 10000)\n",
        "    plt.rcParams.update(plt.rcParamsDefault)\n",
        "    %matplotlib inline\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    plt.style.use(\"seaborn-paper\")\n",
        "    plt.figure(figsize=(10,10))\n",
        "    foldername=str(ML_type)+\"_rocdata\"\n",
        "    rocdata=os.path.join(path_type,folder,\"Results\",foldername)\n",
        "    try:\n",
        "        make=os.mkdir(rocdata)\n",
        "    except:\n",
        "        pass\n",
        "    for i, (train, test) in enumerate(cv.split(principalDf_train, yi_train)):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        aucs_d = []\n",
        "        classifier.fit(principalDf_train[train], yi_train[train])\n",
        "\n",
        "\n",
        "        try:\n",
        "            probas_=classifier.predict_proba(principalDf_train[test])\n",
        "            fpr, tpr, thresholds = metrics.roc_curve(yi_train[test], probas_[:, 1])\n",
        "\n",
        "        except Exception as e:\n",
        "    # ... PRINT THE ERROR MESSAGE ... #\n",
        "            print(e)\n",
        "            probas_=classifier.decision_function(principalDf_train[test])\n",
        "            fpr, tpr, thresholds = metrics.roc_curve(yi_train[test], probas_)\n",
        "\n",
        "\n",
        "        print(\"type tpr\" +str(type(tpr)) )\n",
        "\n",
        "\n",
        "\n",
        "        fpr = pd.Series(fpr)\n",
        "        tpr= pd.Series(tpr)\n",
        "        thresholds= pd.Series(thresholds)\n",
        "\n",
        "        fprname=\"fpr_cv\"+str(i)+\".xlsx\"\n",
        "\n",
        "        filename=os.path.join(rocdata,fprname)\n",
        "\n",
        "        fpr.to_excel(filename)\n",
        "\n",
        "        tprname=\"tpr_cv\"+str(i)+\".xlsx\"\n",
        "\n",
        "        tprfilename=os.path.join(rocdata,tprname)\n",
        "\n",
        "        tpr.to_excel(tprfilename)\n",
        "\n",
        "        thresholdsname=\"thresholds_cv\"+str(i)+\".xlsx\"\n",
        "\n",
        "        thresholdsfilename=os.path.join(rocdata,thresholdsname)\n",
        "\n",
        "        thresholds.to_excel(thresholdsfilename)\n",
        "\n",
        "        y_pred=classifier.predict(principalDf_train[test])\n",
        "\n",
        "\n",
        "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
        "        tprs[-1][0] = 0.0\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "\n",
        "        print(\"AUC check  usual \",roc_auc )\n",
        "        aucs.append(roc_auc)\n",
        "#         plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
        "#              label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
        "\n",
        "#         testauc=metrics.roc_auc_score(y[test], probas_[:, 1])\n",
        "#         print(i, roc_auc, testauc)\n",
        "        acc = metrics.balanced_accuracy_score(yi_train[test], y_pred)\n",
        "        accs.append(acc)\n",
        "\n",
        "#         rc=metrics.recall_score(yi_train[test], y_pred)\n",
        "\n",
        "#         rcs.append(rc)\n",
        "\n",
        "\n",
        "#         interp_tpr=np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
        "#         interp_tpr[0] = 0.0\n",
        "#         tprs.append(interp_tpr)\n",
        "#         aucs.append(viz.roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
        "         label='Chance', alpha=.8)\n",
        "\n",
        "\n",
        "    mean_tpr = np.mean(tprs, axis=0)\n",
        "    mean_tpr[-1] = 1.0\n",
        "    mean_auc = np.mean(aucs)\n",
        "    std_auc = np.std(aucs)\n",
        "    alpha = .95\n",
        "\n",
        "    lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
        "    print(lower_upper_q,(mean_auc),(std_auc))\n",
        "    ci = stats.norm.ppf(\n",
        "        lower_upper_q,\n",
        "        loc=mean_auc,\n",
        "        scale=std_auc)\n",
        "\n",
        "    ci[ci > 1] = 1\n",
        "\n",
        "\n",
        "#     CI=1.96*std_auc/math.sqrt(5)\n",
        "\n",
        "    AUCU=ci[1]\n",
        "    if AUCU>=1.0:\n",
        "        AUCU=1.0\n",
        "    AUCL=ci[0]\n",
        "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
        "             label=r'Mean CV ROC (AUC = {0:.2f} (95% CI {1:.2f}-{2:.2f})'.format(mean_auc,AUCL,AUCU),\n",
        "             lw=2, alpha=.8)\n",
        "\n",
        "    std_tpr = np.std(tprs, axis=0)\n",
        "\n",
        "    CI_tpr=1.96*std_tpr/math.sqrt(5)\n",
        "    tprs_upper = np.minimum(mean_tpr + CI_tpr, 1)\n",
        "    tprs_lower = np.maximum(mean_tpr - CI_tpr, 0)\n",
        "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
        "                     label=r'$\\pm$ 95% CI')\n",
        "\n",
        "#     classifier.fit(principalDf_train, yi_train)\n",
        "\n",
        "#     test and val\n",
        "    yi_pred=classifier.predict(principalDf_itest)\n",
        "\n",
        "\n",
        "    try:\n",
        "        probas_=classifier.predict_proba(principalDf_itest)\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(yi_test, probas_[:, 1])\n",
        "        predictions=probas_[:, 1]\n",
        "\n",
        "    except:\n",
        "        probas_=classifier.decision_function(principalDf_itest)\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(yi_test, probas_)\n",
        "        predictions=probas_\n",
        "\n",
        "    fpr = pd.Series(fpr)\n",
        "    tpr= pd.Series(tpr)\n",
        "    roc_auc_i = auc(fpr, tpr)\n",
        "    print(\"AUCI check usual method\", roc_auc_i)\n",
        "    auc_i,ci_i=CIauc(yi_test,predictions)\n",
        "    print(\"AUCI check delong\",  auc_i)\n",
        "    print(\"AUCI CI check delong\",  ci_i)\n",
        "    df_delong=df_delong.append({\"Label\":'PCA', \"ML Type\":str(ML_type), \"Dataset\":\"Test\",\"Ground Truth\":[yi_test], \"Prediction\":[yi_pred], \"AUC\":roc_auc_i,\"CI\":ci_i},ignore_index=True)\n",
        "\n",
        "#     aucs.append(roc_auc)\n",
        "    acc_i = metrics.balanced_accuracy_score(yi_test, yi_pred)\n",
        "#     rc_i=metrics.recall_score(yi_test, yi_pred)\n",
        "#     accs.append(acc)\n",
        "\n",
        "\n",
        "    plt.plot(fpr, tpr, color='g',\n",
        "             label=r'Test ROC (AUC = {0:.2f} (95% CI {1:.2f}-{2:.2f})'.format(roc_auc_i,ci[0],ci[1]),\n",
        "             lw=2, alpha=.8)\n",
        "\n",
        "    ye_pred=classifier.predict(principalDf_ext)\n",
        "\n",
        "\n",
        "    try:\n",
        "        probas_=classifier.predict_proba(principalDf_ext)\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(y_ext, probas_[:, 1])\n",
        "        predictions=probas_[:, 1]\n",
        "    except Exception as e:\n",
        "    # ... PRINT THE ERROR MESSAGE ... #\n",
        "        print(e)\n",
        "        probas_=classifier.decision_function(principalDf_ext)\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(y_ext, probas_)\n",
        "        predictions=probas_\n",
        "    fpr = pd.Series(fpr)\n",
        "    tpr= pd.Series(tpr)\n",
        "    roc_auc_e = auc(fpr, tpr)\n",
        "    print(\"AUCe check usual\", roc_auc_e)\n",
        "    auc_e,ci_e=CIauc(y_ext,predictions)\n",
        "    print(\"AUCe check delong\",  auc_e)\n",
        "    print(\"AUCe CI check delong\",   ci_e)\n",
        "    df_delong=df_delong.append({\"Label\":'PCA', \"ML Type\":str(ML_type), \"Dataset\":\"Val\",\"Ground Truth\":[y_ext], \"Prediction\":[ye_pred], \"AUC\":roc_auc_e,\"CI\":ci_e},ignore_index=True)\n",
        "\n",
        "#     aucs.append(roc_auc)\n",
        "#     print(y_ext.shape,y_pred.shape)\n",
        "    acc_e = metrics.balanced_accuracy_score(y_ext, ye_pred)\n",
        "#     rc_e=metrics.recall_score(y_ext, ye_pred)\n",
        "#     accs.append(acc)\n",
        "\n",
        "\n",
        "\n",
        "    yc_pred=classifier.predict(principalDf_cases)\n",
        "\n",
        "    print(\" len(yc_pred), len(y_cases), type(yc_pred), type(y_cases_app)\")\n",
        "    yc_pred = pd.DataFrame(yc_pred)\n",
        "    print(len(yc_pred), len(y_cases_app), type(yc_pred), type(y_cases_app))\n",
        "    y_cases_app = y_cases_app.reset_index(drop=True)\n",
        "    yc_pred = yc_pred.reset_index(drop=True)\n",
        "    cases=pd.concat([y_cases_app,yc_pred], axis=1)\n",
        "    print(type(y_cases_app),type(yc_pred))\n",
        "\n",
        "\n",
        "\n",
        "    casesfoldername=str(ML_type)+\"_rocdata\"\n",
        "    casesdata=os.path.join(path_type,folder,\"Results\",casesfoldername)\n",
        "    try:\n",
        "        make=os.mkdir(casesdata)\n",
        "    except:\n",
        "        pass\n",
        "    cases.to_excel(os.path.join(casesdata, str(ML_type) + \"pca.xlsx\"))\n",
        "\n",
        "    plt.plot(fpr, tpr, color='k',\n",
        "             label=r'Validation ROC (AUC = {0:.2f} (95% CI {1:.2f}-{2:.2f})'.format(roc_auc_e,ci[0],ci[1]),\n",
        "             lw=2, alpha=.8)\n",
        "\n",
        "    plt.xlim([-0.05, 1.05])\n",
        "    plt.ylim([-0.05, 1.05])\n",
        "\n",
        "\n",
        "    plt.yticks(fontsize=14)\n",
        "    plt.xticks(fontsize=14)\n",
        "\n",
        "    plt.xlabel('False Positive Rate',fontsize=18)\n",
        "    plt.ylabel('True Positive Rate',fontsize=18)\n",
        "\n",
        "    plt.legend(loc=\"lower right\", prop={'size': 14})\n",
        "    ROCpicname=  str(ML_type)+\"_\" +str(label)+\"_\"+ str(dataframe.name)+\"_\"+\"ROC.jpg\"\n",
        "\n",
        "    fname=os.path.join(path_type,folder,\"Figures\", ROCpicname)\n",
        "    print(fname)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(fname, bbox_inches = \"tight\", dpi=300,quality=95)\n",
        "    print(fname)\n",
        "    plt.clf()\n",
        "\n",
        "#        --------------------------------------\n",
        "    mean_acc=np.mean(accs)\n",
        "    acc_CI=1.96*np.std(accs, axis=0)/math.sqrt(5)\n",
        "\n",
        "\n",
        "#     print(vr,  num_comp, v,tv,svr,mean_acc, acc_CI,mean_auc, CI,mean_rc,rc_CI, roc_auc_i, acc_i, roc_auc_e, acc_e)\n",
        "    return(vr,  num_comp, v,tv,svr,prms_best,mean_acc, acc_CI,mean_auc, ci, roc_auc_i,ci_i, acc_i, roc_auc_e,ci_e, acc_e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTOpV9wRrJY0"
      },
      "outputs": [],
      "source": [
        "from skopt import BayesSearchCV"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "2SnjcHYWrJY0"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHu_nhZqrJY0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK1CX1fRrJY1"
      },
      "outputs": [],
      "source": [
        "\n",
        "path_fs=os.path.join(path, \"Feature_Selection\")\n",
        "path_harm_pca=os.path.join(path_fs, \"Harmonised\")\n",
        "path_org_pca=os.path.join(path_fs, \"Original\")\n",
        "for dataframe in dfs:\n",
        "    df_data_pca= pd.DataFrame(columns= [\"Param\", \"Value\"])\n",
        "    df_pca_params= pd.DataFrame(columns= [\"ML Type\", \"Params\"])\n",
        "\n",
        "    df_data_pcaml= pd.DataFrame(columns= [\"ML Type\", \"ACC_Training\",\"ACC CI\",\"AUC Training\",\"AUC CI\",\"ACC Test\",\"AUC Test\",\"AUC CI Test\",\"ACC Val\",\"AUC Val\",\"AUC CI Val\"])\n",
        "\n",
        "    if \"Harm\" in dataframe.name:\n",
        "\n",
        "        path_type = path_harm_pca\n",
        "    if \"Org\" in dataframe.name:\n",
        "        path_type = path_org_pca\n",
        "    if \"BL\" in dataframe.name:\n",
        "\n",
        "        folder = \"Baseline\"\n",
        "    if \"GCA\" in dataframe.name:\n",
        "        folder = \"GCA\"\n",
        "    plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "    plt.rc('legend', fontsize=10)    # legend fontsize\n",
        "    na=[]\n",
        "    label=\"pca\"\n",
        "    path_pca=path_type\n",
        "#     print(dataframe.name)\n",
        "    mltypes=[\"rf\",\"lgr\",\"svm\", \"dt\",\"gpc\",\"sgd\",\"perc\",\"pasagr\",\"nnet\",\"kneigh\"]\n",
        "\n",
        "    for mlt in mltypes:\n",
        "        print(mlt)\n",
        "#         try:\n",
        "        vr,  num_comp, v,tv,svr,prms_best,mean_acc, acc_CI,mean_auc, ci, roc_auc_i,ci_i, acc_i, roc_auc_e,ci_e, acc_e=PrinCA(dataframe,mlt, folder, path_pca, PCAparams)\n",
        "        df_data_pca=df_data_pca.append ({\"Param\": str(dataframe.name) + \" PCA Variance Ratio\", \"Value\":vr}, ignore_index=True)\n",
        "        df_data_pca=df_data_pca.append ({\"Param\": str(dataframe.name) + \" PCA Cumulative Variance Ratio\", \"Value\":svr}, ignore_index=True)\n",
        "        df_data_pca=df_data_pca.append ({\"Param\": str(dataframe.name) + \" PCA Variance\", \"Value\":v}, ignore_index=True)\n",
        "        df_data_pca=df_data_pca.append ({\"Param\": str(dataframe.name) + \" PCA Total Variance\", \"Value\":tv}, ignore_index=True)\n",
        "        df_data_pca=df_data_pca.append ({\"Param\": str(dataframe.name) + \" PCA Number of Components\", \"Value\":num_comp}, ignore_index=True)\n",
        "#         finalDf.to_csv(os.path.join(path_pca,folder, \"Results\", \"PCA_comp.csv\"))\n",
        "#         finalDf.name=\"finalDf\"\n",
        "\n",
        "\n",
        "        df_data_pcaml=df_data_pcaml.append ({\"ML Type\": str(mlt),\"ACC Training\":mean_acc,\"ACC CI\":acc_CI,\"AUC Training\":mean_auc,\"AUC CI\":ci, \"ACC Test\":acc_i,  \"AUC Test\":roc_auc_i,\"AUC CI Test\":ci_i,\"ACC Val\":acc_e,\"AUC Val\":roc_auc_e, \"AUC CI Val\":ci_e}, ignore_index=True)\n",
        "#         except:\n",
        "#              pass\n",
        "        df_pca_params=df_pca_params.append({\"ML Type\": str(mlt), \"Params\": str(prms_best)},ignore_index=True)\n",
        "\n",
        "\n",
        "    decimals = pd.Series([3, 3,3,3,3,3,3,3,3, 3], index=[  \"ACC_Training\",\"ACC CI\",\"AUC Training\",\"AUC CI\",\"ACC Test\",\"AUC Test\",\"AUC CI Test\",\"ACC Val\",\"AUC Val\",\"AUC CI Val\"])\n",
        "\n",
        "    df_data_pcaml=df_data_pcaml.round(decimals)\n",
        "\n",
        "    df_data_pca.to_excel(os.path.join(path_pca,folder,\"Results\", str(label) +str(dataframe.name) +\"_values.xlsx\"))\n",
        "    df_data_pcaml.to_excel(os.path.join(path_pca,folder,\"Results\", str(label) +str(dataframe.name) +\"classifier_performance.xlsx\"))\n",
        "    df_pca_params.to_excel(os.path.join(path_pca,folder,\"Results\", str(label) +str(dataframe.name) +\"_mlparameters.xlsx\"))\n",
        "\n",
        "    print(os.path.join(path_pca,folder,\"Results\", str(label) +str(dataframe.name) +\"classifier_performance.txt\"))\n",
        "    f = open(os.path.join(path_pca,folder,\"Results\", str(label) +str(dataframe.name) +\"classifier_performance.txt\"), \"a\")\n",
        "    print(df_data_pcaml.to_latex(), file=f)\n",
        "    f.close()\n",
        "\n",
        "    f = open(os.path.join(path_pca,folder,\"Results\", str(label) +str(dataframe.name) +\"PCAparams.txt\"), \"a\")\n",
        "    print(PCAparams.to_latex(), file=f)\n",
        "    f.close()\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxlIv00ZrJY2"
      },
      "outputs": [],
      "source": [
        "excelpath = os.path.join(path, \"delongsinput.xlsx\")\n",
        "df_delong.to_excel(excelpath, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LR0wHNDhrJY2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKv564_DrJY2"
      },
      "outputs": [],
      "source": [
        "df_delong"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBWVhSZlrJY2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "844BI0-nrJY2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKGvtmQKrJY2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03oga3KurJY2"
      },
      "outputs": [],
      "source": [
        "def plotaccauc(df_accauc, path):\n",
        "\n",
        "    with sns.axes_style(\"white\"):\n",
        "        plt.rcParams.update(plt.rcParamsDefault)\n",
        "        %matplotlib inline\n",
        "\n",
        "        plt.style.use(\"seaborn-deep\")\n",
        "        plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "\n",
        "        Acc_means = tuple(list(df_accauc['ACC_Training'].round(2)))\n",
        "        Acc_CI = tuple(list(df_accauc['ACC_CI'].round(2)))\n",
        "        AUC_means = tuple(list(df_accauc['AUC_Training'].round(2)))\n",
        "        AUC_CI = tuple(list(df_accauc['AUC_CI'].round(2)))\n",
        "        Feature = df_accauc['Feature']\n",
        "\n",
        "        Feature = [f.replace('original_', '') for f in Feature]\n",
        "        Feature = [f.replace('_', ' ') for f in Feature]\n",
        "        Feature = [f.replace('gldm', 'GLDM') for f in Feature]\n",
        "        Feature = [f.replace('glrlm', 'GLRLM') for f in Feature]\n",
        "        Feature = [f.replace('glszm', 'GLSZM') for f in Feature]\n",
        "        Feature = [f.replace('glcm', 'GLCM') for f in Feature]\n",
        "        Feature = [f.replace('ngtdm', 'NGTDM') for f in Feature]\n",
        "        Features = list(Feature)\n",
        "\n",
        "\n",
        "\n",
        "        # printing original list\n",
        "#         print(\"The original list : \" + str(Features))\n",
        "\n",
        "        res = []\n",
        "\n",
        "        # loop to iterate all strings\n",
        "        for e in Features:\n",
        "            el=e.split()\n",
        "            ele=el[1]\n",
        "            temp = [[]]\n",
        "            for char in ele:\n",
        "\n",
        "                # checking for upper case character\n",
        "                if char.isupper():\n",
        "                    temp.append([])\n",
        "\n",
        "                # appending character at latest list\n",
        "                temp[-1].append(char)\n",
        "\n",
        "            # joining lists after adding space\n",
        "            result=(' '.join(''.join(ele) for ele in temp))\n",
        "            result1 = el[0]+ \" \" + result\n",
        "            result1=result1.replace(\"90th\",\"90th Percentile\")\n",
        "            result1=result1.replace(\"  \",\"\\n\")\n",
        "            result1=result1.replace(\" \",\"\\n\")\n",
        "\n",
        "            print(result1)\n",
        "            res.append(result1)\n",
        "\n",
        "\n",
        "        # printing result\n",
        "#         print(\"The space added list of strings : \" + str(res))\n",
        "        Feature = tuple(list(res))\n",
        "\n",
        "\n",
        "        data_a = df_accauc['list auc']\n",
        "        data_b = df_accauc['list acc']\n",
        "        print(data_b)\n",
        "\n",
        "        ticks = Feature\n",
        "\n",
        "        def set_box_color(bp, color):\n",
        "            plt.setp(bp['boxes'], color=color)\n",
        "            plt.setp(bp['whiskers'], color=color)\n",
        "            plt.setp(bp['caps'], color=color)\n",
        "            plt.setp(bp['medians'], color=color)\n",
        "\n",
        "        plt.figure()\n",
        "\n",
        "        bpl = plt.boxplot(data_a, positions=np.array(range(len(data_a)))*2.0-0.4, sym='', widths=0.6)\n",
        "        bpr = plt.boxplot(data_b, positions=np.array(range(len(data_b)))*2.0+0.4, sym='', widths=0.6)\n",
        "        set_box_color(bpl, '#D7191C') # colors are from http://colorbrewer2.org/\n",
        "        set_box_color(bpr, '#2C7BB6')\n",
        "\n",
        "        # draw temporary red and blue lines and use them to create a legend\n",
        "        plt.plot([], c='#D7191C', label='AUC')\n",
        "        plt.plot([], c='#2C7BB6', label='Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
        "        plt.xlim(-2, len(ticks)*2)\n",
        "        plt.ylim(0, 1.1)\n",
        "#         plt.tight_layout()\n",
        "\n",
        "        plt.savefig(path, bbox_inches='tight', dpi=300,quality=95)\n",
        "        plt.show()\n",
        "        plt.clf()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QQOUbgurJY2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyeT83oErJY3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# def plotfeature(sliced, y_d,ML_type, label, dataframe):\n",
        "\n",
        "# #     get sliced from def ML\n",
        "#     plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "#     plt.rc('legend', fontsize=10)\n",
        "\n",
        "\n",
        "#     xa = sliced.loc[y_d == float(1)]\n",
        "#     ya = sliced.loc[y_d == float(0)]\n",
        "#     for i, column in enumerate(xa.columns):\n",
        "#         x=xa[column].values\n",
        "#         y=ya[column].values\n",
        "\n",
        "#         xmax=np.amax(x)\n",
        "#         ymax=np.amax(y)\n",
        "#         xmin=np.amin(x)\n",
        "#         ymin=np.amin(y)\n",
        "#         xymax=max(xmax,ymax)\n",
        "#         xymin=min(xmin,ymin)\n",
        "\n",
        "\n",
        "\n",
        "#         bins = np.linspace(xymin,xymax, 50)\n",
        "#         plt.hist([x, y], bins, rwidth=0.5, label=['LVV', 'Control'])\n",
        "# #         plt.hist(x, bins, alpha=0.5)\n",
        "# #         plt.hist(y, bins, alpha=0.5 )\n",
        "#         plt.legend(loc='upper right', fontsize=14)\n",
        "#         plt.ylabel('Feature Frequency', fontsize=18)\n",
        "#         plt.xlabel('Feature Values', fontsize=18)\n",
        "#         plt.tick_params(labelsize=14)\n",
        "\n",
        "#         plt.style.use('seaborn-deep')\n",
        "# #         comment out style if pale purples preferred\n",
        "\n",
        "#         plt.legend(loc='upper right', fontsize=14)\n",
        "#         n=dataframe.name\n",
        "\n",
        "#         figpic=str(ML_type) +str(label)+str(n)+str(column)+\"featureplot.jpg\"\n",
        "#         figpath=os.path.join(path_type,folder,\"Figures\",figpic)\n",
        "\n",
        "\n",
        "#         plt.savefig(figpath, bbox_inches='tight', dpi=300,quality=95)\n",
        "#         plt.clf()\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLzp6z2lrJY3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-ZtpJ1FrJY3"
      },
      "outputs": [],
      "source": [
        "def lgrfeature(dataframe, path, params):\n",
        "    global df_delong\n",
        "\n",
        "\n",
        "    X_ext= dataframe.loc[dataframe['Dataset'] == float(2.0)]\n",
        "    X_cases= dataframe\n",
        "\n",
        "    Xi_test= dataframe.loc[dataframe['Dataset'] == float(3.0)]\n",
        "    Xi_train= dataframe.loc[dataframe['Dataset'] == float(1.0)]\n",
        "#     print(X_int.shape)\n",
        "    yi_train=Xi_train['Diagnosis']\n",
        "    yi_test=Xi_test['Diagnosis']\n",
        "    y_ext=X_ext['Diagnosis']\n",
        "    y_cases=X_cases['Diagnosis']\n",
        "\n",
        "    y_cases_app=X_cases.loc[:,'Patient':'Dataset']\n",
        "\n",
        "\n",
        "    Xi_test = Xi_test.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "    Xi_train = Xi_train.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "    X_ext = X_ext.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "    X_cases= X_cases.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "\n",
        "    flgr = pd.DataFrame(columns= [\"Feature\", \"Params\", 'list acc','list auc',\"ACC Training\",\"ACC CI\",\"AUC Training\",\"AUC CI\",\"ACC Test\",\"AUC Test\",\"AUC Test CI\",\"ACC Val\",\"AUC Val\",\"AUC Val CI\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i, column in enumerate(Xi_test.columns):\n",
        "\n",
        "        print('type Xtrain')\n",
        "        print(type(Xi_train))\n",
        "        x_name=Xi_train[column]\n",
        "#         print(type(Xi_train))\n",
        "        X=x_name.values\n",
        "\n",
        "        X=X.reshape(-1, 1)\n",
        "        print(X.shape)\n",
        "        print(type(X))\n",
        "        y=yi_train  # Labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        cl=LogisticRegression()\n",
        "        prms=[{'max_iter': [10, 10000],\n",
        "        'C': [1.0,4.0],\n",
        "         'dual': [False],\n",
        "         'solver': [\"liblinear\"],\n",
        "               'random_state':[1],\n",
        "               \"penalty\":[\"l2\",\"l1\",None],\n",
        "               'tol': [1e-7,1e-1],\n",
        "               'fit_intercept': [True, False],\n",
        "               'intercept_scaling': [1,5],\n",
        "\n",
        "         'penalty': ['l1', 'l2']}]\n",
        "\n",
        "\n",
        "\n",
        "        opt=BayesSearchCV(cl,prms, n_iter=64, cv=5,refit=True,return_train_score=True)\n",
        "        opt=opt.fit(X,y)\n",
        "\n",
        "\n",
        "        print(\"optimised\")\n",
        "        print(x_name)\n",
        "        print(opt.best_score_)\n",
        "        prms_best= opt.best_params_\n",
        "        print(prms_best)\n",
        "        print(type(prms_best))\n",
        "    #     clf=cl\n",
        "    #     clf.fit(X,y)\n",
        "\n",
        "\n",
        "    #     pkl_filename = str(ML_type)+\"_\" +str(label)+\"_\"+ str(dataframe.name)+\"_model.pkl\"\n",
        "    #     pkl_save=os.path.join(path_type,folder,pkl_filename)\n",
        "    #     with open(pkl_save, 'wb') as file:\n",
        "    #         pickle.dump(clf, file)\n",
        "\n",
        "\n",
        "        cv = StratifiedKFold(n_splits=5)\n",
        "\n",
        "        classifier=cl\n",
        "        classifier=classifier.set_params(**prms_best)\n",
        "        tprs = []\n",
        "        aucs = []\n",
        "        rcs=[]\n",
        "        accs=[]\n",
        "\n",
        "        mean_fpr = np.linspace(0, 1, 10000)\n",
        "#         plt.rcParams.update(plt.rcParamsDefault)\n",
        "#         %matplotlib inline\n",
        "\n",
        "#         plt.style.use(\"seaborn-paper\")\n",
        "#         plt.figure(figsize=(10,10))\n",
        "\n",
        "        for i, (train, test) in enumerate(cv.split(X, y)):\n",
        "             # transform the training data column\n",
        "\n",
        "            classifier.fit(X[train], y[train])\n",
        "            try:\n",
        "                probas_=classifier.predict_proba(X[test])\n",
        "                fpr, tpr, thresholds = metrics.roc_curve(y[test], probas_[:, 1])\n",
        "\n",
        "            except:\n",
        "                probas_=classifier.decision_function(X[test])\n",
        "                fpr, tpr, thresholds = metrics.roc_curve(y[test], probas_)\n",
        "#             print(\"type tpr\" +str(type(tpr)) )\n",
        "\n",
        "\n",
        "            y_pred=classifier.predict(X[test])\n",
        "\n",
        "\n",
        "            tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
        "            tprs[-1][0] = 0.0\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            aucs.append(roc_auc)\n",
        "#             plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
        "#                  label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
        "\n",
        "            testauc=metrics.roc_auc_score(y[test], probas_[:, 1])\n",
        "#             print(i, roc_auc, testauc)\n",
        "            acc = metrics.balanced_accuracy_score(y[test], y_pred)\n",
        "            accs.append(acc)\n",
        "            rc=metrics.recall_score(y[test], y_pred)\n",
        "            rcs.append(rc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #         interp_tpr=np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
        "    #         interp_tpr[0] = 0.0\n",
        "    #         tprs.append(interp_tpr)\n",
        "    #         aucs.append(viz.roc_auc)\n",
        "#         plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
        "#              label='Chance', alpha=.8)\n",
        "\n",
        "\n",
        "        mean_tpr = np.mean(tprs, axis=0)\n",
        "        mean_tpr[-1] = 1.0\n",
        "\n",
        "        mean_auc = np.mean(aucs)\n",
        "        std_auc = np.std(aucs)\n",
        "        alpha = .95\n",
        "\n",
        "        lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
        "        print(lower_upper_q,(mean_auc),(std_auc))\n",
        "        ci = stats.norm.ppf(\n",
        "            lower_upper_q,\n",
        "            loc=mean_auc,\n",
        "            scale=std_auc)\n",
        "\n",
        "        ci[ci > 1] = 1\n",
        "\n",
        "\n",
        "        mean_acc=np.mean(accs)\n",
        "        acc_CI=1.96*np.std(accs, axis=0)/math.sqrt(5)\n",
        "        mean_rc=np.mean(rcs)\n",
        "        rc_CI=1.96*np.std(rcs, axis=0)/math.sqrt(5)\n",
        "\n",
        "        print('type Xtest')\n",
        "        print(type(Xi_test))\n",
        "        col=str(column)\n",
        "        print(col)\n",
        "#\n",
        "        print(Xi_test.shape)\n",
        "        Xi_test_=Xi_test[col].values\n",
        "        print(Xi_test_.shape)\n",
        "#         Xi_test_=x_name.values\n",
        "\n",
        "        Xi_test_=Xi_test_.reshape(-1, 1)\n",
        "#         y=yi_train  # Labels\n",
        "        classifier.fit(X, y)\n",
        "\n",
        "        yi_pred=classifier.predict(Xi_test_)\n",
        "\n",
        "        print(Xi_test_.shape)\n",
        "        try:\n",
        "            probas_=classifier.predict_proba(Xi_test_)\n",
        "            print(len(probas_))\n",
        "            fpr, tpr, thresholds = metrics.roc_curve(yi_test, probas_[:, 1])\n",
        "            predictions=probas_[:, 1]\n",
        "        except:\n",
        "            probas_=classifier.decision_function(Xi_test)\n",
        "            print(len(probas_))\n",
        "            fpr, tpr, thresholds = metrics.roc_curve(yi_test, probas_)\n",
        "            predictions=probas_\n",
        "\n",
        "\n",
        "        fpr = pd.Series(fpr)\n",
        "        tpr= pd.Series(tpr)\n",
        "        roc_auc_i = auc(fpr, tpr)\n",
        "        print(\"AUCI check usual method\", roc_auc_i)\n",
        "        auc_i,ci_i=CIauc(yi_test,predictions)\n",
        "        print(\"AUCI check delong\",  auc_i)\n",
        "        print(\"AUCI CI check delong\",  ci_i)\n",
        "        df_delong=df_delong.append({\"Label\":col, \"ML Type\":'Lgr', \"Dataset\":\"Test\",\"Ground Truth\":[yi_test], \"Prediction\":[predictions], \"AUC\":roc_auc_i,\"CI\":ci_i},ignore_index=True)\n",
        "\n",
        "        acc_i = metrics.balanced_accuracy_score(yi_test, yi_pred)\n",
        "        rc_i=metrics.recall_score(yi_test, yi_pred)\n",
        "    #     accs.append(acc)\n",
        "\n",
        "\n",
        "#         Xi_test=Xi_test.reset_index(drop=True)\n",
        "        print(X_ext.shape)\n",
        "        X_ext_=X_ext[col].values\n",
        "        print(X_ext_.shape)\n",
        "#         Xi_test_=x_name.values\n",
        "\n",
        "        X_ext_=X_ext_.reshape(-1, 1)\n",
        "#         y=yi_train  # Labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ye_pred=classifier.predict(X_ext_)\n",
        "\n",
        "\n",
        "        try:\n",
        "            probas_=classifier.predict_proba(X_ext_)\n",
        "            fpr, tpr, thresholds = metrics.roc_curve(y_ext, probas_[:, 1])\n",
        "            predictions=probas_[:, 1]\n",
        "\n",
        "        except:\n",
        "            probas_=classifier.decision_function(X_ext_)\n",
        "            fpr, tpr, thresholds = metrics.roc_curve(y_ext, probas_)\n",
        "            predictions=probas_\n",
        "\n",
        "        fpr = pd.Series(fpr)\n",
        "        tpr= pd.Series(tpr)\n",
        "        roc_auc_e = auc(fpr, tpr)\n",
        "        print(\"AUCe check usual\", roc_auc_e)\n",
        "        auc_e,ci_e=CIauc(y_ext,predictions)\n",
        "        print(\"AUCe check delong\",  auc_e)\n",
        "        print(\"AUCe CI check delong\",   ci_e)\n",
        "        df_delong=df_delong.append({\"Label\":col, \"ML Type\":'Lgr', \"Dataset\":\"Validation\",\"Ground Truth\":[y_ext], \"Prediction\":[predictions], \"AUC\":roc_auc_e,\"CI\":ci_e},ignore_index=True)\n",
        "\n",
        "        acc_e = metrics.balanced_accuracy_score(y_ext, ye_pred)\n",
        "        rc_e=metrics.recall_score(y_ext, ye_pred)\n",
        "\n",
        "\n",
        "\n",
        "        X_cases_=X_cases[col].values\n",
        "\n",
        "\n",
        "\n",
        "        X_cases_=X_cases_.reshape(-1, 1)\n",
        "\n",
        "\n",
        "\n",
        "        yc_pred=classifier.predict(X_cases_)\n",
        "\n",
        "        print(\" len(yc_pred), len(y_cases), type(yc_pred), type(y_cases_app)\")\n",
        "        yc_pred = pd.DataFrame(yc_pred)\n",
        "        print(len(yc_pred), len(y_cases_app), type(yc_pred), type(y_cases_app))\n",
        "        y_cases_app = y_cases_app.reset_index(drop=True)\n",
        "        yc_pred = yc_pred.reset_index(drop=True)\n",
        "        cases=pd.concat([y_cases_app,yc_pred], axis=1)\n",
        "        print(type(y_cases_app),type(yc_pred))\n",
        "\n",
        "\n",
        "\n",
        "        casesfoldername=str(col)+\"_rocdata\"\n",
        "        casesdata=os.path.join(path,folder,\"Results\",casesfoldername)\n",
        "        try:\n",
        "            make=os.mkdir(casesdata)\n",
        "        except:\n",
        "            pass\n",
        "        cases.to_excel(os.path.join(casesdata, str(col) + \"_lgr.xlsx\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        flgr=flgr.append ({\"Feature\": str(column),\"Params\":prms_best,'list acc':accs,'list auc':aucs, \"ACC Training\":mean_acc,\"ACC CI\":acc_CI, \"AUC Training\":mean_auc,\"AUC CI\":ci,\"ACC Test\":acc_i,\"AUC Test\":roc_auc_i,\"AUC Test CI\":ci_i,\"ACC Val\":acc_e ,\"AUC Val\":roc_auc_e, \"AUC Val CI\":ci_e,}, ignore_index=True)\n",
        "\n",
        "        plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    excelpath = os.path.join(path, folder,\"Results\", \"LGR_ind_features.xlsx\")\n",
        "    flgr.to_excel(excelpath, index=False)\n",
        "\n",
        "    flgr_thracc=flgr[flgr[\"ACC Training\"]>0.5]\n",
        "    flgr_auc=flgr_thracc.sort_values(by=[\"AUC Training\"],ascending=False)\n",
        "    auc_5=flgr_auc.iloc[0:5]\n",
        "\n",
        "#\n",
        "    figurepath = os.path.join(path, folder,\"Figures\", \"LGR_auc_top5.jpg\")\n",
        "#     plotaccauc(auc_5,figurepath)\n",
        "\n",
        "\n",
        "    excelpath = os.path.join(path, folder,\"Results\",  \"LGR_auc_top5.xlsx\")\n",
        "    auc_5.to_excel(excelpath, index=False)\n",
        "    f = open(os.path.join(path,folder,\"Results\", \"lgrauc5.txt\"), \"a\")\n",
        "    print(auc_5.to_latex(), file=f)\n",
        "    f.close()\n",
        "\n",
        "    features=auc_5[\"Feature\"]\n",
        "    features=features.tolist()\n",
        "    corrlist=features\n",
        "\n",
        "\n",
        "\n",
        "    rows=['original_firstorder_90Percentile', 'original_firstorder_Maximum','original_firstorder_Mean','SUV 50','SUV 60','SUV 70','SUV 80','SUV 90']\n",
        "    corrlist=corrlist+rows\n",
        "    lgrSUV=flgr[flgr['Feature'].isin(rows)]\n",
        "    cleanup = {\"Feature\": {'original_firstorder_90Percentile':\"SUV 90th Percentile\", 'original_firstorder_Maximum':\"SUV Max\",'original_firstorder_Mean':\"SUV Mean\"}}\n",
        "\n",
        "    lgrSUV.replace(cleanup, inplace=True)\n",
        "\n",
        "    figurepath = os.path.join(path, folder,\"Figures\", \"LGR_SUV.jpg\")\n",
        "#     plotaccauc(lgrSUV, figurepath)\n",
        "    excelpath = os.path.join(path, folder, \"Results\",\"lgr_SUV.xlsx\")\n",
        "    lgrSUV.to_excel(excelpath, index=False)\n",
        "    f = open(os.path.join(path,folder,\"Results\",\"lgrSUV.txt\"), \"a\")\n",
        "    print(lgrSUV.to_latex(), file=f)\n",
        "    f.close()\n",
        "\n",
        "    index = dataframe.index\n",
        "    print(index)\n",
        "    print(corrlist)\n",
        "    print(dataframe.shape)\n",
        "    corrdf=dataframe.loc[:,corrlist]\n",
        "    print(corrdf.shape)\n",
        "\n",
        "    corrMatrix = corrdf.corr()\n",
        "\n",
        "    excelpath = os.path.join(path, folder, \"Results\",\"corrmatrixtop5plussuv.xlsx\")\n",
        "    corrMatrix.to_excel(excelpath, index=False)\n",
        "    f = open(os.path.join(path,folder,\"Results\",\"corrmatrixtop5plussuv.txt\"), \"a\")\n",
        "    print(corrMatrix.to_latex(), file=f)\n",
        "    f.close()\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1PLzMOBrJY3"
      },
      "outputs": [],
      "source": [
        "excelpath = os.path.join(path, \"delongsinput.xlsx\")\n",
        "df_delong.to_excel(excelpath, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "KZ0jolXerJY3"
      },
      "outputs": [],
      "source": [
        "for dataframe in dfs:\n",
        "    plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "    plt.rc('legend', fontsize=10)    # legend fontsize\n",
        "    if \"Harm\" in dataframe.name:\n",
        "\n",
        "        path_type = path_harm\n",
        "    if \"Org\" in dataframe.name:\n",
        "        path_type = path_org\n",
        "    if \"BL\" in dataframe.name:\n",
        "\n",
        "        folder = \"Baseline\"\n",
        "    if \"GCA\" in dataframe.name:\n",
        "        folder = \"GCA\"\n",
        "\n",
        "    lgrfeature(dataframe,path_type, LRparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f4b2xG3rJY3"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def mwu(dataframe, path, folder):\n",
        "\n",
        "    X_ext= dataframe.loc[dataframe['Dataset'] == float(2.0)]\n",
        "    X_int= dataframe.loc[dataframe['Dataset'] == float(1.0)]\n",
        "    y_int=X_int['Diagnosis']\n",
        "    y_ext=X_ext['Diagnosis']\n",
        "\n",
        "\n",
        "#     X_int = X_int.loc[:,\"original_firstorder_10Percentile\":\"SUV 90\"]\n",
        "#     X_ext = X_ext.loc[:,\"original_firstorder_10Percentile\":\"SUV 90\"]\n",
        "\n",
        "\n",
        "    xa = X_int.loc[X_int['Diagnosis'] == float(1)]\n",
        "    ya = X_int.loc[X_int['Diagnosis'] == float(0)]\n",
        "    mwu = pd.DataFrame(columns= [\"Feature\", \"Mean LVV Value\", \"Mean Control Value\", \"Std Dev LVV\", \"Std Dev Control\", \"Ustatistic\", \"P\", \"Cohens d Value (Effect Size)\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    xa = xa.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "    ya = ya.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i, column in enumerate(xa.columns):\n",
        "\n",
        "\n",
        "\n",
        "        x=xa[column].values\n",
        "        y=ya[column].values\n",
        "\n",
        "        xt=type(x[3])\n",
        "\n",
        "\n",
        "        if \"str\" not in str(xt) :\n",
        "\n",
        "\n",
        "            try:\n",
        "                statistic, pvalue = mannwhitneyu((x), (y))\n",
        "            except:\n",
        "                statistic= \"failed\"\n",
        "                pvalue= \"failed\"\n",
        "\n",
        "            def cohen_d(x,y):\n",
        "                nx = len(x)\n",
        "                ny = len(y)\n",
        "                dof = nx + ny - 2\n",
        "                return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof)\n",
        "\n",
        "\n",
        "            # print(str(column) + ',' + str(mean(x)) + ',' + str(mean(y)) + ',' + str(std(x, ddof=1)) + ',' + str(std(y, ddof=1)) + ',' + str(statistic) + ',' + str(pvalue) + ',' + str(cohen_d(x,y)))\n",
        "\n",
        "            a=column\n",
        "            try:\n",
        "                b=np.mean(x)\n",
        "\n",
        "            except:\n",
        "                b=\"NaN\"\n",
        "            try:\n",
        "                c=np.mean(y)\n",
        "            except:\n",
        "                c=\"NaN\"\n",
        "            try:\n",
        "                d=np.std(x, ddof=1)\n",
        "            except:\n",
        "                d=\"NaN\"\n",
        "\n",
        "            try:\n",
        "                e=np.std(y, ddof=1)\n",
        "            except:\n",
        "                e=\"NaN\"\n",
        "            try:\n",
        "                f=statistic\n",
        "            except:\n",
        "                f=\"NaN\"\n",
        "\n",
        "            try:\n",
        "                g=pvalue\n",
        "            except:\n",
        "                g=\"NaN\"\n",
        "\n",
        "            try:\n",
        "                h=cohen_d(x,y)\n",
        "            except:\n",
        "                h=\"NaN\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            mwu=mwu.append ({\"Feature\": a, \"Mean LVV Value\": b, \"Mean Control Value\": c, \"Std Dev LVV\": d, \"Std Dev Control\": e, \"Ustatistic\": f, \"P\": g, \"Cohens d Value (Effect Size)\": h }, ignore_index=True)\n",
        "\n",
        "\n",
        "    excelpath = os.path.join(path, folder,\"Results\", \"mwu.xlsx\")\n",
        "    mwu.to_excel(excelpath, index=False)\n",
        "    failed=[\"failed\"]\n",
        "    mwun = mwu.loc[~mwu['P'].isin(failed)]\n",
        "    sig = mwun.loc[mwun['P'] < (0.00049)]\n",
        "    no_sig_features= len(sig[\"P\"])\n",
        "\n",
        "\n",
        "    mwusorted=sig.sort_values(by=['P'])\n",
        "    mwu5=mwusorted.iloc[0:5]\n",
        "    excelpath = os.path.join(path, folder,\"Results\", \"mwu_abovep.xlsx\")\n",
        "    mwu5.to_excel(excelpath, index=False)\n",
        "\n",
        "\n",
        "#     features=mwu5[\"Feature\"]\n",
        "#     features=features.tolist()\n",
        "\n",
        "#     mwu5.name=\"mwu5\"\n",
        "\n",
        "#     label=\"mwu5\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     df_data_mwu5= pd.DataFrame(columns= [\"ML Type\", \"ACC_CV\",\"ACC_CI\",\"AUC_CV\",\"AUC_CI\"])\n",
        "\n",
        "\n",
        "#     mltypes=[\"rf\",\"lgr\",\"svm\",\"lr\", \"ridge\",\"lasso\",\"dt\",\"gpc\",\"el_net\",\"lars\",\"omp\",\"bayrid\",\"sgd\",\"perc\",\"pasagr\",\"nnet\",\"kneigh\"]\n",
        "# #     path_pca=os.path.join(path, \"PCA\")\n",
        "# # linear regression ridge lasso el_net lars omp bayrid regression not classifiers so deleted\n",
        "# #    nearcent does not have proba so just delete if needed, kneigh close enough\n",
        "\n",
        "\n",
        "\n",
        "#     for mlt in mltypes:\n",
        "#         try:\n",
        "#             s_mean, s_ci,mean_auc, CI=ML(mlt, dataframe,path_type,folder,features, label)\n",
        "#             df_data_mwu5=df_data_mwu5.append ({\"ML Type\": str(mlt),\"ACC_CV\":s_mean,\"ACC_CI\":s_ci,\"AUC_CV\":mean_auc,\"AUC_CI\":CI }, ignore_index=True)\n",
        "#         except:\n",
        "#              pass\n",
        "\n",
        "#     excelpath = os.path.join(path, folder)\n",
        "#     df_data_mwu5.to_excel(os.path.join(excelpath,\"Results\",  str(label) +str(dataframe.name) +\"classifier_performance.xlsx\"))\n",
        "\n",
        "    rows=[ 'original_firstorder_90Percentile', 'original_firstorder_Maximum','original_firstorder_Mean','SUV 50','SUV 60','SUV 70','SUV 80','SUV 90']\n",
        "\n",
        "    mwuSUV=mwu[mwu['Feature'].isin(rows)]\n",
        "    cleanup = {\"Feature\": {'original_firstorder_90Percentile':\"SUV 90th Percentile\", 'original_firstorder_Maximum':\"SUV Max\",'original_firstorder_Mean':\"SUV Mean\"} }\n",
        "\n",
        "    mwuSUV.replace(cleanup, inplace=True)\n",
        "    excelpath = os.path.join(path, folder,\"Results\",\"mwu_SUV.xlsx\")\n",
        "    mwuSUV.to_excel(excelpath, index=False)\n",
        "    f = open(os.path.join(path,folder,\"Results\",\"mwuSUV.txt\"), \"a\")\n",
        "    print(mwuSUV.to_latex(), file=f)\n",
        "    f.close()\n",
        "\n",
        "    xext = X_ext.loc[X_ext['Diagnosis'] == float(1)]\n",
        "    yext = X_ext.loc[X_ext['Diagnosis'] == float(0)]\n",
        "    mwuext = pd.DataFrame(columns= [\"Feature\", \"Mean LVV Value\", \"Mean Control Value\", \"Std Dev LVV\", \"Std Dev Control\", \"Ustatistic\", \"P\", \"Cohens d Value (Effect Size)\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    xext = xext.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "    yext = yext.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    for i, column in enumerate(xext.columns):\n",
        "\n",
        "\n",
        "\n",
        "        x=xext[column].values\n",
        "        y=yext[column].values\n",
        "\n",
        "        xt=type(x[3])\n",
        "\n",
        "\n",
        "        if \"str\" not in str(xt) :\n",
        "\n",
        "\n",
        "            try:\n",
        "                statistic, pvalue = mannwhitneyu((x), (y))\n",
        "            except:\n",
        "                statistic= \"failed\"\n",
        "                pvalue= \"failed\"\n",
        "\n",
        "            def cohen_d(x,y):\n",
        "                nx = len(x)\n",
        "                ny = len(y)\n",
        "                dof = nx + ny - 2\n",
        "                return (np.mean(x) - np.mean(y)) / np.sqrt(((nx-1)*np.std(x, ddof=1) ** 2 + (ny-1)*np.std(y, ddof=1) ** 2) / dof)\n",
        "\n",
        "\n",
        "            # print(str(column) + ',' + str(mean(x)) + ',' + str(mean(y)) + ',' + str(std(x, ddof=1)) + ',' + str(std(y, ddof=1)) + ',' + str(statistic) + ',' + str(pvalue) + ',' + str(cohen_d(x,y)))\n",
        "\n",
        "            a=column\n",
        "            try:\n",
        "                b=np.mean(x)\n",
        "\n",
        "            except:\n",
        "                b=\"NaN\"\n",
        "            try:\n",
        "                c=np.mean(y)\n",
        "            except:\n",
        "                c=\"NaN\"\n",
        "            try:\n",
        "                d=np.std(x, ddof=1)\n",
        "            except:\n",
        "                d=\"NaN\"\n",
        "\n",
        "            try:\n",
        "                e=np.std(y, ddof=1)\n",
        "            except:\n",
        "                e=\"NaN\"\n",
        "            try:\n",
        "                f=statistic\n",
        "            except:\n",
        "                f=\"NaN\"\n",
        "\n",
        "            try:\n",
        "                g=pvalue\n",
        "            except:\n",
        "                g=\"NaN\"\n",
        "\n",
        "            try:\n",
        "                h=cohen_d(x,y)\n",
        "            except:\n",
        "                h=\"NaN\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            mwuext=mwuext.append ({\"Feature\": a, \"Mean LVV Value\": b, \"Mean Control Value\": c, \"Std Dev LVV\": d, \"Std Dev Control\": e, \"Ustatistic\": f, \"P\": g, \"Cohens d Value (Effect Size)\": h }, ignore_index=True)\n",
        "\n",
        "\n",
        "    excelpath = os.path.join(path, folder,\"Results\", \"mwuext.xlsx\")\n",
        "    mwuext.to_excel(excelpath, index=False)\n",
        "    failed=[\"failed\"]\n",
        "    mwun = mwuext.loc[~mwuext['P'].isin(failed)]\n",
        "    sig = mwun.loc[mwun['P'] < (0.00049)]\n",
        "    no_sig_features= len(sig[\"P\"])\n",
        "\n",
        "\n",
        "    mwusorted=sig.sort_values(by=['P'])\n",
        "    mwu5=mwusorted.iloc[0:5]\n",
        "    excelpath = os.path.join(path, folder,\"Results\", \"mwu_abovepext.xlsx\")\n",
        "    mwu5.to_excel(excelpath, index=False)\n",
        "\n",
        "\n",
        "#\n",
        "    rows=[ 'original_firstorder_90Percentile', 'original_firstorder_Maximum','original_firstorder_Mean','SUV 50','SUV 60','SUV 70','SUV 80','SUV 90']\n",
        "\n",
        "    mwuSUVext=mwuext[mwuext['Feature'].isin(rows)]\n",
        "    cleanup = {\"Feature\": {'original_firstorder_90Percentile':\"SUV 90th Percentile\", 'original_firstorder_Maximum':\"SUV Max\",'original_firstorder_Mean':\"SUV Mean\"} }\n",
        "\n",
        "    mwuSUVext.replace(cleanup, inplace=True)\n",
        "    excelpath = os.path.join(path, folder,\"Results\",\"mwu_SUVext.xlsx\")\n",
        "    mwuSUVext.to_excel(excelpath, index=False)\n",
        "    f = open(os.path.join(path,folder,\"Results\",\"mwuSUVext.txt\"), \"a\")\n",
        "    print(mwuSUVext.to_latex(), file=f)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "    return()\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfkgcYPWrJY3"
      },
      "outputs": [],
      "source": [
        "for dataframe in dfs:\n",
        "    plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "    plt.rc('legend', fontsize=10)    # legend fontsize\n",
        "    if \"Harm\" in dataframe.name:\n",
        "\n",
        "        path_type = path_harm\n",
        "    if \"Org\" in dataframe.name:\n",
        "        path_type = path_org\n",
        "    if \"BL\" in dataframe.name:\n",
        "\n",
        "        folder = \"Baseline\"\n",
        "    if \"GCA\" in dataframe.name:\n",
        "        folder = \"GCA\"\n",
        "    mwu(dataframe,path_type, folder)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNUXgq_WrJY3"
      },
      "outputs": [],
      "source": [
        "def feat_red(path, folder,dataframe):\n",
        "    from sklearn import feature_selection\n",
        "    if \"Harm\" in dataframe.name:\n",
        "\n",
        "        path_type = path_harm\n",
        "    if \"Org\" in dataframe.name:\n",
        "        path_type = path_org\n",
        "    if \"BL\" in dataframe.name:\n",
        "\n",
        "        folder = \"Baseline\"\n",
        "    if \"GCA\" in dataframe.name:\n",
        "        folder = \"GCA\"\n",
        "    LGRres=pd.read_excel(os.path.join(path_type,folder,\"Results\",\"LGR_ind_features.xlsx\"))\n",
        "    mwures=pd.read_excel(os.path.join(path_type,folder,\"Results\",\"mwu.xlsx\"))\n",
        "\n",
        "    feat_res=LGRres\n",
        "    from math import log10, floor\n",
        "    def round_sig(x, sig=3):\n",
        "        return round(x, sig-int(floor(log10(abs(x))))-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    pval=[]\n",
        "    for i,row in LGRres.iterrows():\n",
        "        feat=row[\"Feature\"]\n",
        "        for i,row in mwures.iterrows():\n",
        "            feat_2=row[\"Feature\"]\n",
        "            if feat==feat_2:\n",
        "                p_val=row[\"P\"]\n",
        "                p_val=round_sig(p_val)\n",
        "                pval.append(p_val)\n",
        "\n",
        "\n",
        "    feat_res['p value'] = pval\n",
        "\n",
        "\n",
        "    feat_res=feat_res.sort_values(by=['AUC Training'], ascending=False)\n",
        "    print(feat_res.head())\n",
        "    full_featres=feat_res\n",
        "    print(full_featres.head())\n",
        "\n",
        "#     replacing =  {'original_': '','_':' ','gldm': 'GLDM','glrlm': 'GLRLM','glszm': 'GLSZM','glcm': 'GLCM','ngtdm': 'NGTDM'}\n",
        "\n",
        "#     full_featres=full_featres.replace(replacing)\n",
        "    print(type(full_featres))\n",
        "\n",
        "#     cleanup = {\"Feature\": {'original_firstorder_90Percentile':\"SUV 90th Percentile\", 'original_firstorder_Maximum':\"SUV Max\",'original_firstorder_Mean':\"SUV Mean\"}}\n",
        "\n",
        "#     lgrSUV.replace(cleanup, inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "#     -----------\n",
        "    print(feat_res.head())\n",
        "    feat_res=feat_res.reset_index(drop=True)\n",
        "\n",
        "    pmax=0.5/len(LGRres)\n",
        "    feat_res = feat_res[feat_res[\"AUC Training\"] >= 0.5]\n",
        "    feat_res = feat_res[feat_res[\"ACC Training\"] > 0.5]\n",
        "    feat_res = feat_res[feat_res[\"p value\"] < pmax]\n",
        "    feat_res=feat_res.reset_index(drop=True)\n",
        "    features=feat_res[\"Feature\"]\n",
        "    features=features.tolist()\n",
        "    features_rank=feat_res.reset_index()\n",
        "    features_rank=features_rank.loc[:,\"index\":\"Feature\"]\n",
        "\n",
        "\n",
        "    X = dataframe[dataframe.columns.intersection(features)]\n",
        "    corr_matrix = X.corr().abs()\n",
        "    to_drop_90=[]\n",
        "    to_drop_70=[]\n",
        "    to_drop_85=[]\n",
        "    to_drop_80=[]\n",
        "    to_drop_95=[]\n",
        "    # print(corr_matrix['original_glszm_SmallAreaHighGrayLevelEmphasis'].sort_values(ascending=False).head(50))\n",
        "    for i, row in features_rank.iterrows():\n",
        "        feat=row[\"Feature\"]\n",
        "        rank_1=row[\"index\"]\n",
        "        for i, column in enumerate(corr_matrix.columns):\n",
        "            coef=corr_matrix.at[feat,column]\n",
        "            col_index=features_rank[features_rank[\"Feature\"]==column].index.values\n",
        "\n",
        "    #         rank_2=features_rank[col_index:\"Feature\"]\n",
        "            rank_2=float(col_index)\n",
        "\n",
        "            if coef>0.9:\n",
        "                if rank_1<rank_2:\n",
        "                    to_drop_90.append(column)\n",
        "\n",
        "            if coef>0.95:\n",
        "                if rank_1<rank_2:\n",
        "                    to_drop_95.append(column)\n",
        "            if coef>0.70:\n",
        "                if rank_1<rank_2:\n",
        "                    to_drop_70.append(column)\n",
        "            if coef>0.80:\n",
        "                if rank_1<rank_2:\n",
        "                    to_drop_80.append(column)\n",
        "            if coef>0.85:\n",
        "                if rank_1<rank_2:\n",
        "                    to_drop_85.append(column)\n",
        "\n",
        "    to_drop = pd.Series(to_drop_70)\n",
        "    to_drop=to_drop.drop_duplicates()\n",
        "    features_sel=features_rank[~features_rank.Feature.isin(to_drop)]\n",
        "    features_sel_70=features_sel[\"Feature\"]\n",
        "\n",
        "\n",
        "    to_drop = pd.Series(to_drop_80)\n",
        "    to_drop=to_drop.drop_duplicates()\n",
        "    features_sel=features_rank[~features_rank.Feature.isin(to_drop)]\n",
        "    features_sel_80=features_sel[\"Feature\"]\n",
        "\n",
        "\n",
        "    to_drop = pd.Series(to_drop_90)\n",
        "    to_drop=to_drop.drop_duplicates()\n",
        "    features_sel=features_rank[~features_rank.Feature.isin(to_drop)]\n",
        "    features_sel_90=features_sel[\"Feature\"]\n",
        "\n",
        "\n",
        "    to_drop = pd.Series(to_drop_85)\n",
        "    to_drop=to_drop.drop_duplicates()\n",
        "    features_sel=features_rank[~features_rank.Feature.isin(to_drop)]\n",
        "    features_sel_85=features_sel[\"Feature\"]\n",
        "\n",
        "\n",
        "    to_drop = pd.Series(to_drop_95)\n",
        "    to_drop=to_drop.drop_duplicates()\n",
        "    features_sel=features_rank[~features_rank.Feature.isin(to_drop)]\n",
        "    features_sel_95=features_sel[\"Feature\"]\n",
        "\n",
        "    print(features_sel_90.shape, features_sel_95.shape, features_sel_80.shape,features_sel_70.shape,features_sel_85.shape)\n",
        "\n",
        "    return(features, features_sel_90, features_sel_95, features_sel_80,features_sel_70,features_sel_85)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y_4x-45rJY3"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectFromModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdPqMOWDrJY4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def ML(ML_type, dataframe, path,folder, features,label,params):\n",
        "    global df_delong\n",
        "\n",
        "\n",
        "\n",
        "    X_ext= dataframe.loc[dataframe['Dataset'] == float(2.0)]\n",
        "    X_cases= dataframe\n",
        "    Xi_test= dataframe.loc[dataframe['Dataset'] == float(3.0)]\n",
        "    Xi_train= dataframe.loc[dataframe['Dataset'] == float(1.0)]\n",
        "#     print(X_int.shape)\n",
        "    yi_train=Xi_train['Diagnosis']\n",
        "    yi_test=Xi_test['Diagnosis']\n",
        "    y_ext=X_ext['Diagnosis']\n",
        "    y_cases=X_cases['Diagnosis']\n",
        "\n",
        "    y_cases_app=X_cases.loc[:,'Patient':'Dataset']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if len(features)==0 :\n",
        "\n",
        "\n",
        "        Xi_train = Xi_train.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "        Xi_test = Xi_test.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "        X_ext = X_ext.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "        X_cases=X_cases.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "\n",
        "    else:\n",
        "        sliced = dataframe[dataframe.columns.intersection(features)]\n",
        "        Xi_train = Xi_train[Xi_train.columns.intersection(features)]\n",
        "        Xi_test = Xi_test[Xi_test.columns.intersection(features)]\n",
        "        X_ext = X_ext[X_ext.columns.intersection(features)]\n",
        "        X_cases=X_cases[X_cases.columns.intersection(features)]\n",
        "\n",
        "    plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "    plt.rc('legend', fontsize=10)\n",
        "#     a=list(sliced.columns.values)\n",
        "\n",
        "    Xi_train=Xi_train.to_numpy()\n",
        "    Xi_test=Xi_test.to_numpy()\n",
        "    X_ext=X_ext.to_numpy()\n",
        "\n",
        "    X_cases=X_cases.to_numpy()\n",
        "\n",
        "    # fit on training data column\n",
        "\n",
        "\n",
        "\n",
        "    if ML_type == \"rf\":\n",
        "        cl=RandomForestClassifier()\n",
        "        prms=[{'n_estimators': [10, 2000],\n",
        "                'bootstrap': [True, False],\n",
        "                 'max_depth': [10,   1000],\n",
        "                 'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "               'random_state':[1],\n",
        "                 'min_samples_leaf': [1, 10],\n",
        "                 'min_samples_split': [2, 10]}]\n",
        "    if ML_type == \"lgr\":\n",
        "        cl=LogisticRegression()\n",
        "        prms=[{'max_iter': [10, 10000],\n",
        "        'C': [1.0,4.0],\n",
        "         'dual': [False],\n",
        "         'solver': [\"liblinear\"],\n",
        "               'random_state':[1],\n",
        "               \"penalty\":[\"l2\",\"l1\",None],\n",
        "               'tol': [1e-7,1e-1],\n",
        "               'fit_intercept': [True, False],\n",
        "               'intercept_scaling': [1,5],\n",
        "\n",
        "         'penalty': ['l1', 'l2']}]\n",
        "    if ML_type == \"svm\":\n",
        "        cl=svm.SVC(probability=True)\n",
        "        prms=[{'C': [1,10],\n",
        "                'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "               'random_state':[1],\n",
        "                 'gamma': ['scale', 'auto']}]\n",
        "    if ML_type == \"lr\":\n",
        "        cl=linear_model.LinearRegression()\n",
        "        prms=[{'fit_intercept': [True, False],\n",
        "               'random_state':[1],\n",
        "                'normalize': [True, False]}]\n",
        "    if ML_type == \"ridge\":\n",
        "        cl=linear_model.RidgeClassifierCV()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'normalize': [True, False],\n",
        "               'random_state':[1],\n",
        "                 'scoring': ['accuracy', 'roc_auc'],\n",
        "                 'cv': [1,5]}]\n",
        "    if ML_type == \"lasso\":\n",
        "        cl=linear_model.Lasso()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'normalize': [True, False],\n",
        "                 'alpha': [0.1,2.0],\n",
        "               'random_state':[1],\n",
        "                 'max_iter': [5, 1000],\n",
        "                 'selection': ['cyclic', 'random']}]\n",
        "    if ML_type == \"el_net\":\n",
        "        cl=linear_model.ElasticNetCV()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "            'normalize': [True, False],\n",
        "             'alpha': [0.0, 1.0],\n",
        "               'tol': [1e-5,1e-3],\n",
        "             'max_iter': [5,2000],\n",
        "             'selection': ['cyclic', 'random'],\n",
        "            'l1_ratio': [0.0,  1.0],\n",
        "               'random_state':[1],\n",
        "            'positive': [True, False]}]\n",
        "    if ML_type == \"lars\":\n",
        "        cl=linear_model.LassoLars()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'normalize': [True, False],\n",
        "               'random_state':[1],\n",
        "                 'alpha': [0.0,2.0],\n",
        "                 'max_iter': [ 5, 1000],\n",
        "\n",
        "                }]\n",
        "    if ML_type == \"omp\":\n",
        "        cl=linear_model.OrthogonalMatchingPursuit()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "               'random_state':[1],\n",
        "                'normalize': [True, False]}]\n",
        "    if ML_type == \"bayrid\":\n",
        "        cl=linear_model.BayesianRidge()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'normalize': [True, False],\n",
        "               'random_state':[1],\n",
        "                 'alpha_1': [1e-7,1e-5],\n",
        "                 'alpha_2': [1e-7,1e-5],\n",
        "                 'lambda_1': [1e-7,1e-5],\n",
        "              'lambda_2':[1e-7,1e-5]}]\n",
        "    if ML_type == \"sgd\":\n",
        "        cl=linear_model.SGDClassifier()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'average': [True, False],\n",
        "                 'loss': ['hinge','log'],\n",
        "               'random_state':[1],\n",
        "                 'max_iter': [ 5, 1000],\n",
        "                 'alpha': [0.001,0.1]}]\n",
        "    if ML_type == \"perc\":\n",
        "        cl=linear_model.Perceptron()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'penalty': ['l2', 'l1','elasticnet','None'],\n",
        "                 'alpha': [0.01,0.1],\n",
        "               'random_state':[1],\n",
        "                 'max_iter': [ 5, 1000]}]\n",
        "    if ML_type == \"pasagr\":\n",
        "        cl=linear_model.PassiveAggressiveClassifier()\n",
        "        prms=[{ 'fit_intercept': [True, False],\n",
        "                'C': [0.0,2.0],\n",
        "                 'max_iter': [5, 2000],\n",
        "               'random_state':[1],\n",
        "                 'average': [True, False]}]\n",
        "    if ML_type == \"nnet\":\n",
        "        cl=MLPClassifier()\n",
        "        prms=[{  'alpha': [0.00001,0.1],\n",
        "#                'random_state':[1],\n",
        "#                  'hidden_layer_sizes': [(5,), (10,), (100,), (500,)],\n",
        "                 'max_iter': [100,  1000]}]\n",
        "    if ML_type == \"kneigh\":\n",
        "        cl=KNeighborsClassifier()\n",
        "        prms=[{ 'n_neighbors': [2,5],\n",
        "                'weights': ['uniform', 'distance'],\n",
        "\n",
        "                 'algorithm': ['auto','kd_tree', 'brute','ball_tree'],\n",
        "                 'leaf_size': [10,50]}]\n",
        "    if ML_type == \"dt\":\n",
        "        cl=tree.DecisionTreeClassifier()\n",
        "        prms=[{  'criterion': [\"gini\", \"entropy\"],\n",
        "                 'splitter': ['best', 'random'],\n",
        "\n",
        "                 'max_leaf_nodes': [2,100],\n",
        "               'random_state':[1],\n",
        "               'min_impurity_decrease': [0.0, 0.5],\n",
        "\n",
        "\n",
        "                 'ccp_alpha': [0.0,  1.0],\n",
        "               'max_depth': [5,    1000],\n",
        "                 'max_features': ['auto', 'sqrt', 'log2', None],\n",
        "                 'min_samples_leaf': [2,  50],\n",
        "                 'min_samples_split': [2,10]}]\n",
        "    if ML_type == \"gpc\":\n",
        "        kernel = 1.0 * RBF(1.0)\n",
        "        cl = GaussianProcessClassifier(kernel=kernel)\n",
        "        prms=[{  'max_iter_predict': [10, 2000], 'random_state':[1]}]\n",
        "    if ML_type == \"nearcent\":\n",
        "        cl=NearestCentroid()\n",
        "        prms=[]\n",
        "\n",
        "\n",
        "    opt=BayesSearchCV(cl,prms, n_iter=64, cv=5)\n",
        "    opt=opt.fit(Xi_train,yi_train)\n",
        "\n",
        "\n",
        "    print(\"optimised\")\n",
        "    print(ML_type)\n",
        "    print(opt.best_score_)\n",
        "    prms_best= opt.best_params_\n",
        "    print(prms_best)\n",
        "    print(type(prms_best))\n",
        "\n",
        "\n",
        "    cv = StratifiedKFold(n_splits=5)\n",
        "\n",
        "    classifier=cl\n",
        "    classifier=classifier.set_params(**prms_best)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    tprs = []\n",
        "    aucs = []\n",
        "    rcs=[]\n",
        "    accs=[]\n",
        "\n",
        "    mean_fpr = np.linspace(0, 1, 10000)\n",
        "    plt.rcParams.update(plt.rcParamsDefault)\n",
        "    %matplotlib inline\n",
        "\n",
        "    plt.style.use(\"seaborn-paper\")\n",
        "    plt.figure(figsize=(10,10))\n",
        "    foldername=str(label)+str(ML_type)+\"_rocdata\"\n",
        "    rocdata=os.path.join(path_type,folder,\"Results\",foldername)\n",
        "    try:\n",
        "        make=os.mkdir(rocdata)\n",
        "    except:\n",
        "        pass\n",
        "    for i, (train, test) in enumerate(cv.split(Xi_train, yi_train)):\n",
        "         # transform the training data column\n",
        "\n",
        "        classifier.fit(Xi_train[train], yi_train[train])\n",
        "        try:\n",
        "            probas_=classifier.predict_proba(Xi_train[test])\n",
        "            fpr, tpr, thresholds = metrics.roc_curve(yi_train[test], probas_[:, 1])\n",
        "\n",
        "        except:\n",
        "            probas_=classifier.decision_function(Xi_train[test])\n",
        "            fpr, tpr, thresholds = metrics.roc_curve(yi_train[test], probas_)\n",
        "#         print(\"type tpr\" +str(type(tpr)) )\n",
        "\n",
        "        fpr = pd.Series(fpr)\n",
        "        tpr= pd.Series(tpr)\n",
        "        thresholds= pd.Series(thresholds)\n",
        "        try:\n",
        "            print(classifier.feature_names_in_)\n",
        "\n",
        "            print(classifier.feature_importances_)\n",
        "        except:\n",
        "            pass\n",
        "        fprname=\"fpr_cv\"+str(i)+\".xlsx\"\n",
        "\n",
        "        filename=os.path.join(rocdata,fprname)\n",
        "\n",
        "        fpr.to_excel(filename)\n",
        "\n",
        "        tprname=\"tpr_cv\"+str(i)+\".xlsx\"\n",
        "\n",
        "        tprfilename=os.path.join(rocdata,tprname)\n",
        "\n",
        "        tpr.to_excel(tprfilename)\n",
        "\n",
        "        thresholdsname=\"thresholds_cv\"+str(i)+\".xlsx\"\n",
        "\n",
        "        thresholdsfilename=os.path.join(rocdata,thresholdsname)\n",
        "\n",
        "        thresholds.to_excel(thresholdsfilename)\n",
        "\n",
        "        y_pred=classifier.predict(Xi_train[test])\n",
        "\n",
        "        tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
        "        tprs[-1][0] = 0.0\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        aucs.append(roc_auc)\n",
        "#         plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
        "#              label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
        "\n",
        "#         testauc=metrics.roc_auc_score(y[test], probas_[:, 1])\n",
        "#         print(i, roc_auc, testauc)\n",
        "        acc = metrics.balanced_accuracy_score(yi_train[test], y_pred)\n",
        "        accs.append(acc)\n",
        "        rc=metrics.recall_score(yi_train[test], y_pred)\n",
        "        rcs.append(rc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#         interp_tpr=np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
        "#         interp_tpr[0] = 0.0\n",
        "#         tprs.append(interp_tpr)\n",
        "#         aucs.append(viz.roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
        "         label='Chance', alpha=.8)\n",
        "\n",
        "\n",
        "    mean_tpr = np.mean(tprs, axis=0)\n",
        "    mean_tpr[-1] = 1.0\n",
        "    mean_auc = np.mean(aucs)\n",
        "    std_auc = np.std(aucs)\n",
        "    alpha = .95\n",
        "\n",
        "    lower_upper_q = np.abs(np.array([0, 1]) - (1 - alpha) / 2)\n",
        "    print(lower_upper_q,(mean_auc),(std_auc))\n",
        "    ci = stats.norm.ppf(\n",
        "        lower_upper_q,\n",
        "        loc=mean_auc,\n",
        "        scale=std_auc)\n",
        "\n",
        "    ci[ci > 1] = 1\n",
        "\n",
        "    AUCU=ci[1]\n",
        "    if AUCU>=1.0:\n",
        "        AUCU=1.0\n",
        "    AUCL=ci[0]\n",
        "\n",
        "    plt.plot(mean_fpr, mean_tpr, color='b',\n",
        "             label=r'Mean CV ROC (AUC = {0:.2f} (95% CI {1:.2f}-{2:.2f})'.format(mean_auc,AUCL,AUCU),\n",
        "             lw=2, alpha=.8)\n",
        "\n",
        "    std_tpr = np.std(tprs, axis=0)\n",
        "    CI_tpr=1.96*std_tpr/math.sqrt(5)\n",
        "    tprs_upper = np.minimum(mean_tpr + CI_tpr, 1)\n",
        "    tprs_lower = np.maximum(mean_tpr - CI_tpr, 0)\n",
        "    plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
        "                     label=r'$\\pm$ 95% CI')\n",
        "\n",
        "    classifier.fit(Xi_train, yi_train)\n",
        "    Xi_train_2 = dataframe.loc[:,\"original_shape_Elongation\":\"SUV 90\"]\n",
        "#     if ML_type == \"rf\":\n",
        "#     sel = SelectFromModel(classifier)\n",
        "#     sel.fit(Xi_train, yi_train)\n",
        "# #     sel.get_support()\n",
        "#     selected_feat= Xi_train_2.columns[(sel.get_support())]\n",
        "#     print(len(selected_feat))\n",
        "#     print(selected_feat)\n",
        "\n",
        "\n",
        "    try:\n",
        "        feature_imp = pd.Series(classifier.feature_importances_,index=Xi_train_2.columns).sort_values(ascending=False)\n",
        "        print(feature_imp.head(n=10))\n",
        "    except:\n",
        "        feature_imp=[\"nan\"]\n",
        "\n",
        "#     print(pd.series(sel.estimator_,feature_importances_,.ravel()).hist())\n",
        "#     pd.series(sel.estimator_,feature_importances_,.ravel()).hist()\n",
        "#     features =  list(Xi_train)\n",
        "#     f_i = list(zip(features,classifier.feature_importances_))\n",
        "#     f_i.sort(key = lambda x : x[1])\n",
        "# #     test and val\n",
        "    yi_pred=classifier.predict(Xi_test)\n",
        "\n",
        "\n",
        "    try:\n",
        "        probas_=classifier.predict_proba(Xi_test)\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(yi_test, probas_[:, 1])\n",
        "        predictions=probas_[:, 1]\n",
        "    except:\n",
        "        probas_=classifier.decision_function(Xi_test)\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(yi_test, probas_)\n",
        "        predictions=probas_\n",
        "    df_delong=df_delong.append({\"Label\":label, \"ML Type\":ML_type, \"Dataset\":\"Test\",\"Ground Truth\":[yi_test], \"Prediction\":[predictions]},ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "    fpr = pd.Series(fpr)\n",
        "    tpr= pd.Series(tpr)\n",
        "    roc_auc_i = auc(fpr, tpr)\n",
        "    print(\"AUCI check usual method\", roc_auc_i)\n",
        "    auc_i,ci_i=CIauc(yi_test,predictions)\n",
        "    print(\"AUCI check delong\",  auc_i)\n",
        "    print(\"AUCI CI check delong\",  ci_i)\n",
        "\n",
        "\n",
        "\n",
        "    acc_i = metrics.balanced_accuracy_score(yi_test, yi_pred)\n",
        "    rc_i=metrics.recall_score(yi_test, yi_pred)\n",
        "#     accs.append(acc)\n",
        "\n",
        "    df_delong=df_delong.append({\"Label\":'PCA', \"ML Type\":str(ML_type), \"Dataset\":\"Test\",\"Ground Truth\":[yi_test], \"Prediction\":[yi_pred], \"AUC\":roc_auc_i,\"CI\":ci_i},ignore_index=True)\n",
        "\n",
        "\n",
        "    plt.plot(fpr, tpr, color='g',\n",
        "             label=r'Test ROC (AUC = {0:.2f} (95% CI {1:.2f}-{2:.2f})'.format(roc_auc_i,ci[0],ci[1]),\n",
        "             lw=2, alpha=.8)\n",
        "\n",
        "    ye_pred=classifier.predict(X_ext)\n",
        "\n",
        "\n",
        "    try:\n",
        "        probas_=classifier.predict_proba(X_ext)\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(y_ext, probas_[:, 1])\n",
        "        predictions=probas_[:, 1]\n",
        "    except:\n",
        "        probas_=classifier.decision_function(X_ext)\n",
        "        fpr, tpr, thresholds = metrics.roc_curve(y_ext, probas_)\n",
        "        predictions=probas_\n",
        "    fpr = pd.Series(fpr)\n",
        "    tpr= pd.Series(tpr)\n",
        "    roc_auc_e = auc(fpr, tpr)\n",
        "    print(\"AUCe check usual\", roc_auc_e)\n",
        "    auc_e,ci_e=CIauc(y_ext,predictions)\n",
        "    print(\"AUCe check delong\",  auc_e)\n",
        "    print(\"AUCe CI check delong\",   ci_e)\n",
        "    df_delong=df_delong.append({\"Label\":'PCA', \"ML Type\":str(ML_type), \"Dataset\":\"Val\",\"Ground Truth\":[y_ext], \"Prediction\":[ye_pred], \"AUC\":roc_auc_e,\"CI\":ci_e},ignore_index=True)\n",
        "\n",
        "    acc_e = metrics.balanced_accuracy_score(y_ext, ye_pred)\n",
        "    rc_e=metrics.recall_score(y_ext, ye_pred)\n",
        "#     accs.append(acc)\n",
        "\n",
        "    plt.plot(fpr, tpr, color='k',\n",
        "             label=r'Validation ROC (AUC = {0:.2f} (95% CI {1:.2f}-{2:.2f})'.format(roc_auc_e,ci[0],ci[1]),\n",
        "             lw=2, alpha=.8)\n",
        "\n",
        "\n",
        "    plt.xlim([-0.05, 1.05])\n",
        "    plt.ylim([-0.05, 1.05])\n",
        "\n",
        "\n",
        "    plt.yticks(fontsize=14)\n",
        "    plt.xticks(fontsize=14)\n",
        "\n",
        "    plt.xlabel('False Positive Rate',fontsize=18)\n",
        "    plt.ylabel('True Positive Rate',fontsize=18)\n",
        "\n",
        "    plt.legend(loc=\"lower right\", prop={'size': 14})\n",
        "    ROCpicname=  str(ML_type)+\"_\" +str(label)+\"_\"+ str(dataframe.name)+\"_\"+\"ROC.jpg\"\n",
        "\n",
        "    fname=os.path.join(path_type,folder,\"Figures\", ROCpicname)\n",
        "    print(fname)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(fname, bbox_inches = \"tight\", dpi=300,quality=95)\n",
        "    print(fname)\n",
        "    plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    yc_pred=classifier.predict(X_cases)\n",
        "\n",
        "    print(\" len(yc_pred), len(y_cases), type(yc_pred), type(y_cases_app)\")\n",
        "    yc_pred = pd.DataFrame(yc_pred)\n",
        "    print(len(yc_pred), len(y_cases_app), type(yc_pred), type(y_cases_app))\n",
        "    y_cases_app = y_cases_app.reset_index(drop=True)\n",
        "    yc_pred = yc_pred.reset_index(drop=True)\n",
        "    cases=pd.concat([y_cases_app,yc_pred], axis=1)\n",
        "    print(type(y_cases_app),type(yc_pred))\n",
        "\n",
        "\n",
        "\n",
        "    casesfoldername=str(ML_type)+\"_rocdata\"\n",
        "    casesdata=os.path.join(path_type,folder,\"Results\",casesfoldername)\n",
        "    try:\n",
        "        make=os.mkdir(casesdata)\n",
        "    except:\n",
        "        pass\n",
        "    cases.to_excel(os.path.join(casesdata, str(ML_type) + str(label) +str(dataframe.name)+\"mlcases.xlsx\"))\n",
        "\n",
        "#        --------------------------------------\n",
        "    mean_acc=np.mean(accs)\n",
        "    acc_CI=1.96*np.std(accs, axis=0)/math.sqrt(5)\n",
        "\n",
        "    mean_rc=np.mean(rcs)\n",
        "    rc_CI=1.96*np.std(rcs, axis=0)/math.sqrt(5)\n",
        "\n",
        "\n",
        "# # Load from file\n",
        "# with open(pkl_filename, 'rb') as file:\n",
        "#     pickle_model = pickle.load(file)\n",
        "#     keep for when needed\n",
        "    print(ML_type,mean_acc, acc_CI,mean_auc)\n",
        "    return(prms_best,mean_acc, acc_CI, mean_auc, ci,  acc_i, roc_auc_i,ci_i, acc_e,roc_auc_e, ci_e, feature_imp )\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1yP237PrJY4"
      },
      "outputs": [],
      "source": [
        "path_fs=os.path.join(path, \"Feature_Selection\")\n",
        "path_harm_fs=os.path.join(path_fs, \"Harmonised\")\n",
        "path_org_fs=os.path.join(path_fs, \"Original\")\n",
        "\n",
        "for dataframe in dfs:\n",
        "    plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "    df_fr_params= pd.DataFrame(columns= [\"ML Type\", \"Params\"])\n",
        "\n",
        "    plt.rc('legend', fontsize=10)    # legend fontsize\n",
        "    if \"Harm\" in dataframe.name:\n",
        "\n",
        "        path_type = path_harm_fs\n",
        "\n",
        "        path_type_1 = path_harm\n",
        "    if \"Org\" in dataframe.name:\n",
        "        path_type = path_org_fs\n",
        "        path_type_1 = path_org\n",
        "    if \"BL\" in dataframe.name:\n",
        "\n",
        "        folder = \"Baseline\"\n",
        "    if \"GCA\" in dataframe.name:\n",
        "        folder = \"GCA\"\n",
        "\n",
        "    features, features_sel_90, features_sel_95, features_sel_80,features_sel_70,features_sel_85=feat_red(path_type_1,folder,dataframe)\n",
        "\n",
        "    f2_90 = pd.DataFrame(features_sel_90)\n",
        "\n",
        "#     excelpath = os.path.join(path,\"Feature_Selection\",folder,\"Results\", str(label) + str(dataframe.name) +\"_MLperformance_feature_reduction.xlsx\")\n",
        "    f2_90.to_excel(os.path.join(path_type,folder,\"Results\", str(dataframe.name) +\"corr_feature_reduction90.xlsx\"), index=False)\n",
        "    label=\"feat_sel_corr_90\"\n",
        "    mltypes=[\"rf\",\"lgr\", \"ridge\",\"lasso\",\"dt\",\"gpc\",\"el_net\",\"lars\",\"omp\",\"bayrid\",\"sgd\",\"perc\",\"pasagr\",\"nnet\",\"kneigh\"]\n",
        "\n",
        "    df_data_featsel= pd.DataFrame(columns= [\"ML Type\", \"ACC Training\",\"ACC CI\",\"AUC Training\",\"AUC CI\",\"ACC Test\",\"AUC Test\",\"AUC Test CI\", \"ACC Val\",\"AUC Val\",\"AUC Val CI\", \"Important Features\"])\n",
        "    print('ML')\n",
        "    for mlt in mltypes:\n",
        "\n",
        "        try:\n",
        "            print(mlt)\n",
        "            prms_best,mean_acc, acc_CI, mean_auc, ci,  acc_i, roc_auc_i,ci_i, acc_e,roc_auc_e, ci_e, feature_imp  =ML(mlt, dataframe,path_type,folder,features_sel_90, label,fbparams)\n",
        "\n",
        "#             df_fr_params=df_pca_params.append({\"ML Type\": str(mlt), \"Params\": str(prms_best)},ignore_index=True)\n",
        "\n",
        "            df_data_featsel=df_data_featsel.append ({\"ML Type\": str(mlt),\"ACC Training\":mean_acc,\"ACC CI\":acc_CI,\"AUC Training\":mean_auc,\"AUC CI\":ci, \"ACC Test\":acc_i,  \"AUC Test\":roc_auc_i,\"AUC Test CI\":ci_i,\"ACC Val\":acc_e,\"AUC Val\":roc_auc_e,\"AUC Val CI\":ci_e, \"Important Features\":feature_imp}, ignore_index=True)\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            print(\"pass \"+str(mlt))\n",
        "            pass\n",
        "#     excelpathparams = os.path.join(path_type,folder,\"Results\", str(label) + str(dataframe.name) +\"_MLparams.xlsx\")\n",
        "\n",
        "\n",
        "#     df_fr_params.to_excel(excelpathparams, index=False)\n",
        "\n",
        "    excelpath = os.path.join(path_type,folder,\"Results\", str(label) + str(dataframe.name) +\"_MLperformance_feature_reduction.xlsx\")\n",
        "    df_data_featsel.to_excel(excelpath, index=False)\n",
        "\n",
        "    label=\"rf\"\n",
        "    mltypes=[\"rf\"]\n",
        "    features=[]\n",
        "    df_data_featsel_rf= pd.DataFrame(columns= [\"ML Type\", \"ACC Training\",\"ACC CI\",\"AUC Training\",\"AUC CI\",\"ACC Test\",\"AUC Test\",\"AUC Test CI\", \"ACC Val\",\"AUC Val\",\"AUC Val CI\", \"Important Features\"])\n",
        "    print('ML rf')\n",
        "    for mlt in mltypes:\n",
        "        print(mlt)\n",
        "#         try:\n",
        "\n",
        "        prms_best,mean_acc, acc_CI, mean_auc, ci,  acc_i, roc_auc_i,ci_i, acc_e,roc_auc_e, ci_e, feature_imp  =ML(mlt, dataframe,path_type,folder,features, label,fbparams)\n",
        "\n",
        "#             df_frrf_params=df_pca_params.append({\"ML Type\": str(mlt), \"Params\": str(prms_best)},ignore_index=True)\n",
        "\n",
        "        df_data_featsel_rf=df_data_featsel.append ({\"ML Type\": str(mlt),\"ACC Training\":mean_acc,\"ACC CI\":acc_CI,\"AUC Training\":mean_auc,\"AUC CI\":ci, \"ACC Test\":acc_i,  \"AUC Test\":roc_auc_i,\"AUC Test CI\":ci_i,\"ACC Val\":acc_e,\"AUC Val\":roc_auc_e,\"AUC Val CI\":ci_e, \"Important Features\":feature_imp} , ignore_index=True)\n",
        "#         except:\n",
        "#              pass\n",
        "    excelpathparams = os.path.join(path_type,folder,\"Results\", str(label) + str(dataframe.name) +\"_MLparams.xlsx\")\n",
        "\n",
        "\n",
        "#     df_fr_params.to_excel(excelpathparams, index=False)\n",
        "\n",
        "    excelpath = os.path.join(path_type,folder,\"Results\", str(label) + str(dataframe.name) +\"_MLperformance_feature_reductionwithallrf.xlsx\")\n",
        "    df_data_featsel_rf.to_excel(excelpath, index=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     df_data_pcaml=df_data_pcaml.append ({\"ML Type\": str(mlt),\"ACC_Training\":mean_acc,\"ACC_CI\":acc_CI,\"Recall_Training\":mean_rc,\"Recall_CI\":rc_CI,\"AUC_Training\":mean_auc,\"AUC_CI\":CI, \"ACC_Test\":acc_i,  \"Recall_Test\":rc_i,\"AUC_Test\":roc_auc_i,\"ACC_Val\":acc_e,\"Recall_Val\":rc_e,\"AUC_Val\":roc_auc_e}, ignore_index=True)\n",
        "# #         except:\n",
        "# #              pass\n",
        "#     df_pca_params=df_pca_params.append({\"ML Type\": str(mlt), \"Params\": str(prms_best)},ignore_index=True)\n",
        "\n",
        "\n",
        "#     decimals = pd.Series([3, 3,3,3,3,3,3,3,3, 3,3,3], index=[ \"ACC_Training\",\"ACC_CI\",\"Recall_Training\", \"Recall_CI\",\"AUC_Training\",\"AUC_CI\",\"ACC_Test\",\"Recall_Test\",\"AUC_Test\",\"ACC_Val\",\"Recall_Val\",\"AUC_Val\"])\n",
        "#     df_data_pcaml=df_data_pcaml.round(decimals)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcXe7abQrJY4"
      },
      "outputs": [],
      "source": [
        "excelpath = os.path.join(path, \"delongsinput.xlsx\")\n",
        "df_delong.to_excel(excelpath, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DG5Pe8erJY4"
      },
      "outputs": [],
      "source": [
        "print(\"done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYpAtSmbrJY4"
      },
      "outputs": [],
      "source": [
        "fi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgXXSZtwrJY4"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be6Y7svtrJY4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbxnQJ9-rJY4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IL518AtrJY4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NY2IPUJVrJY4"
      },
      "outputs": [],
      "source": [
        "# mwu=pd.read_excel(\"/Users/mnlmd/Documents/PyradiomicsResults/20201207/20201207-124100/Harmonised/Baseline/Results/mwu.xlsx\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vL1tAOcmrJY5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCt2kXZErJY5"
      },
      "outputs": [],
      "source": [
        "# f = open(os.path.join(\"/Users/mnlmd/Documents/PyradiomicsResults/20201207/20201207-124100/Harmonised\",\"Baseline\",\"Results\",\"mwu.txt\"), \"a\")\n",
        "# print(mwu.to_latex(), file=f)\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1XZF1gorJY5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpoiru_UrJY5"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-Jgql-UrJY5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBvRQyDsrJY5"
      },
      "outputs": [],
      "source": [
        "# excelpath = os.path.join(path, \"df_data.xlsx\")\n",
        "# df_data.to_excel(excelpath, index=False)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IFtM9girJY5"
      },
      "outputs": [],
      "source": [
        "for dataframe in dfs:\n",
        "    if \"Harm\" in dataframe.name:\n",
        "\n",
        "        path_type = path_harm\n",
        "    if \"Org\" in dataframe.name:\n",
        "        path_type = path_org\n",
        "    if \"BL\" in dataframe.name:\n",
        "\n",
        "        folder = \"Baseline\"\n",
        "    if \"GCA\" in dataframe.name:\n",
        "        folder = \"GCA\"\n",
        "\n",
        "\n",
        "    excelpath = os.path.join(path_type, str(dataframe.name) +\".xlsx\")\n",
        "    dataframe.to_excel(excelpath, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXuqvADwrJY5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XuK8poQrJY5"
      },
      "outputs": [],
      "source": [
        "use def CIauc(y_true,y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQ04hH6CrJY5"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "jupyter nbconvert --to html pipeline_step3_20210112.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHUovES2rJY5"
      },
      "outputs": [],
      "source": [
        "d_path= path\n",
        "\n",
        "dest=os.path.join(d_path,str(Date_folder)+\"finish_pipeline_step3.html\")\n",
        "home=\"/Users/mnlmd/Documents/PyradiomicsResults/\"\n",
        "\n",
        "temp=os.path.join(home,\"Template_cpu\")\n",
        "source = os.path.join(temp,\"pipeline_step3_20210112.html\")\n",
        "shutil.move(source, dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfSPvjlxrJY5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZvuw7GxrJY5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9jm5pzjrJY5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oqPsbgPrJY5"
      },
      "outputs": [],
      "source": [
        "def plotaccaucnew(df_accauc, path):\n",
        "\n",
        "    with sns.axes_style(\"white\"):\n",
        "        plt.rcParams.update(plt.rcParamsDefault)\n",
        "        %matplotlib inline\n",
        "\n",
        "#         plt.style.use(\"seaborn-deep\")\n",
        "        plt.rcParams.update({'font.size': 12})\n",
        "\n",
        "        Feature = df_accauc['Feature']\n",
        "\n",
        "        Feature = [f.replace('original_', '') for f in Feature]\n",
        "        Feature = [f.replace('_', ' ') for f in Feature]\n",
        "        Feature = [f.replace('gldm', 'GLDM') for f in Feature]\n",
        "        Feature = [f.replace('glrlm', 'GLRLM') for f in Feature]\n",
        "        Feature = [f.replace('glszm', 'GLSZM') for f in Feature]\n",
        "        Feature = [f.replace('glcm', 'GLCM') for f in Feature]\n",
        "        Feature = [f.replace('ngtdm', 'NGTDM') for f in Feature]\n",
        "#         Feature = [f.replace('firstorder', 'NGTDM') for f in Feature]\n",
        "        Features = list(Feature)\n",
        "\n",
        "\n",
        "\n",
        "        # printing original list\n",
        "#         print(\"The original list : \" + str(Features))\n",
        "\n",
        "        res = []\n",
        "\n",
        "        # loop to iterate all strings\n",
        "        for e in Features:\n",
        "            el=e.split()\n",
        "            ele=el[1]\n",
        "            temp = [[]]\n",
        "            for char in ele:\n",
        "\n",
        "                # checking for upper case character\n",
        "                if char.isupper():\n",
        "                    temp.append([])\n",
        "\n",
        "                # appending character at latest list\n",
        "                temp[-1].append(char)\n",
        "\n",
        "            # joining lists after adding space\n",
        "            result=(' '.join(''.join(ele) for ele in temp))\n",
        "            result1 = el[0]+ \" \" + result\n",
        "            result1=result1.replace(\"90th\",\"90th Percentile\")\n",
        "\n",
        "#             result1=result1.replace(\"  \",\"\\n\")\n",
        "#             result1=result1.replace(\" \",\"\\n\")\n",
        "\n",
        "#             print(result1)\n",
        "            res.append(result1)\n",
        "\n",
        "\n",
        "        # printing result\n",
        "#         print(\"The space added list of strings : \" + str(res))\n",
        "        Feature = tuple(list(res))\n",
        "\n",
        "        aucci=df_accauc['AUC CI']\n",
        "        aucci = [f.replace('[', '') for f in aucci]\n",
        "        aucci = [f.replace(']', '') for f in aucci]\n",
        "        aucci = [f.replace('  ', ' ') for f in aucci]\n",
        "\n",
        "        err = pd.DataFrame(columns = ['lower', 'upper'])\n",
        "        aucci=list(aucci)\n",
        "\n",
        "        for i in range(len(aucci)):\n",
        "            ci=aucci[i]\n",
        "\n",
        "            ci = ci.split(\" \")\n",
        "            auc=df_accauc['AUC Training'][i]\n",
        "            print(ci)\n",
        "\n",
        "            l=auc-float(ci[0])\n",
        "            u=float(ci[1])-auc\n",
        "            err=err.append({'lower':l, 'upper':u}, ignore_index=True)\n",
        "\n",
        "        aucci=np.transpose(err.to_numpy())\n",
        "\n",
        "\n",
        "        aucci=aucci.round(2)\n",
        "        err = pd.DataFrame(columns = ['lower', 'upper'])\n",
        "        auccit=df_accauc['AUC Test CI']\n",
        "        auccit = [f.replace('[', '') for f in auccit]\n",
        "        auccit = [f.replace(']', '') for f in auccit]\n",
        "        auccit = [f.replace('  ', ' ') for f in auccit]\n",
        "\n",
        "        auccit=list(auccit)\n",
        "\n",
        "        for i in range(len(auccit)):\n",
        "            ci=auccit[i]\n",
        "            ci = ci.split(\" \")\n",
        "            auc=df_accauc['AUC Test'][i]\n",
        "            print(ci)\n",
        "\n",
        "            l=auc-float(ci[0])\n",
        "            u=float(ci[1])-auc\n",
        "            err=err.append({'lower':l, 'upper':u}, ignore_index=True)\n",
        "\n",
        "        auccit=np.transpose(err.to_numpy())\n",
        "\n",
        "\n",
        "        auccit=auccit.round(2)\n",
        "\n",
        "        err = pd.DataFrame(columns = ['lower', 'upper'])\n",
        "        aucciv=df_accauc['AUC Val CI']\n",
        "        aucciv = [f.replace('[', '') for f in aucciv]\n",
        "        aucciv = [f.replace(']', '') for f in aucciv]\n",
        "        aucciv = [f.replace('  ', ' ') for f in aucciv]\n",
        "\n",
        "        aucciv=list(aucciv)\n",
        "\n",
        "        for i in range(len(aucciv)):\n",
        "            ci=aucciv[i]\n",
        "            ci = ci.split(\" \")\n",
        "            auc=df_accauc['AUC Val'][i]\n",
        "            print(ci)\n",
        "\n",
        "            l=auc-float(ci[0])\n",
        "            u=float(ci[1])-auc\n",
        "            err=err.append({'lower':l, 'upper':u}, ignore_index=True)\n",
        "\n",
        "        aucciv=np.transpose(err.to_numpy())\n",
        "\n",
        "\n",
        "        aucciv=aucciv.round(2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        Acc_train = tuple(list(df_accauc['ACC Training'].round(2)))\n",
        "        AUC_train = tuple(list(df_accauc['AUC Training'].round(2)))\n",
        "        AUC_CI_train = aucci\n",
        "\n",
        "        Acc_test = tuple(list(df_accauc['ACC Test'].round(2)))\n",
        "        AUC_test = tuple(list(df_accauc['AUC Test'].round(2)))\n",
        "        AUC_CI_test = auccit\n",
        "\n",
        "        Acc_val= tuple(list(df_accauc['ACC Val'].round(2)))\n",
        "        AUC_val = tuple(list(df_accauc['AUC Val'].round(2)))\n",
        "        AUC_CI_val = aucciv\n",
        "\n",
        "\n",
        "\n",
        "#         data_a = df_accauc['list auc']\n",
        "#         data_b = df_accauc['list acc']\n",
        "#         print(data_b)\n",
        "\n",
        "        ticks = Feature\n",
        "        y_pos=np.arange(len(Features))\n",
        "        widthacc=-0.4\n",
        "        widthauc=0.4\n",
        "        fig, ax = plt.subplots()\n",
        "#         ax.barh(y_pos-0.3, Acc_train,height=widthacc, xerr=0, align='center')\n",
        "#         ax.barh(y_pos-0.2, AUC_train, height=widthauc,xerr=aucci, align='center')\n",
        "\n",
        "#         ax.barh(y_pos-0.1, Acc_test,height=widthacc, xerr=0, align='center')\n",
        "#         ax.barh(y_pos+0.1, AUC_test,height=widthauc, xerr=auccit, align='center')\n",
        "\n",
        "\n",
        "        hacc=ax.barh(y_pos, Acc_val, height=widthacc,color = 'black',xerr=0, align='edge')\n",
        "        hauc=ax.barh(y_pos, AUC_val, height=widthauc,xerr=aucciv,color = 'white',edgecolor='black',  align='edge')\n",
        "\n",
        "\n",
        "\n",
        "        ax.set_yticks(y_pos, labels=Feature)\n",
        "        ax.invert_yaxis()  # labels read top-to-bottom\n",
        "        ax.set_xlabel('Diagnostic Performance')\n",
        "        ax.set_ylabel('Features')\n",
        "        ax.bar_label(hauc, fmt=' %.2f')\n",
        "        ax.set_xlim(right=1.11)\n",
        "        ax.legend((hacc, hauc), ('Accuracy', 'AUC'),bbox_to_anchor=(1.02, 1.0), loc='upper left', borderaxespad=2)\n",
        "#         ax.legend(bbox_to_anchor=(1.1, 1.0), loc='upper left', borderaxespad=2)\n",
        "\n",
        "\n",
        "#         def set_box_color(bp, color):\n",
        "#             plt.setp(bp['boxes'], color=color)\n",
        "#             plt.setp(bp['whiskers'], color=color)\n",
        "#             plt.setp(bp['caps'], color=color)\n",
        "#             plt.setp(bp['medians'], color=color)\n",
        "\n",
        "        plt.figure()\n",
        "\n",
        "#         bpl = plt.boxplot(data_a, positions=np.array(range(len(data_a)))*2.0-0.4, sym='', widths=0.6)\n",
        "#         bpr = plt.boxplot(data_b, positions=np.array(range(len(data_b)))*2.0+0.4, sym='', widths=0.6)\n",
        "#         set_box_color(bpl, '#D7191C') # colors are from http://colorbrewer2.org/\n",
        "#         set_box_color(bpr, '#2C7BB6')\n",
        "\n",
        "#         # draw temporary red and blue lines and use them to create a legend\n",
        "#         plt.plot([], c='#D7191C', label='AUC')\n",
        "#         plt.plot([], c='#2C7BB6', label='Accuracy')\n",
        "#         plt.legend()\n",
        "\n",
        "#         plt.xticks(range(0, len(ticks) * 2, 2), ticks)\n",
        "#         plt.xlim(-2, len(ticks)*2)\n",
        "#         plt.ylim(0, 1.1)\n",
        "# #         plt.tight_layout()\n",
        "\n",
        "        plt.savefig(path, bbox_inches='tight', dpi=300,quality=95)\n",
        "        plt.show()\n",
        "        plt.clf()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhMm4URHrJY6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouPc_huhrJY6",
        "outputId": "db5c0cc0-6573-48d8-c603-938bd3eb25c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0.60525241', '1.', '', '', '', '']\n",
            "['0.82905969', '0.98094031']\n",
            "['0.74796553', '1.', '', '', '', '']\n",
            "['0.76930015', '0.9337554', '']\n",
            "['0.76930015', '0.9337554', '']\n",
            "['0.74325379', '1.', '', '', '', '']\n",
            "['0.93713654', '1.', '', '', '', '']\n",
            "['0.77983735', '1.', '', '', '', '']\n",
            "['0.88787315', '1.', '', '', '', '']\n",
            "['0.88787315', '1.', '', '', '', '']\n",
            "['0.81624175', '1.', '', '', '', '']\n",
            "['0.79721404', '0.99988741']\n",
            "['0.78653061', '1.', '', '', '', '']\n",
            "['0.770659', '0.99745694']\n",
            "['0.770659', '0.99745694']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mnlmd/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:199: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"quality\" which is no longer supported as of 3.3 and will become an error in 3.6\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "auc_5=pd.read_excel('/Users/mnlmd/Documents/PyradiomicsResults/20221223/20221223-135010/Original/GCA/Results/LGR_auc_top5.xlsx')\n",
        "\n",
        "figurepath = \"/Users/mnlmd/Documents/PyradiomicsResults/20221223/20221223-135010/LGR_auc_top5.jpg\"\n",
        "plotaccaucnew(auc_5,figurepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WohBSbfNrJY6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sGrDGT7rJY6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrqIc3ODrJY6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5wxYQ14rJY6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN3swvTdrJY6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTBmr_2VrJY6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVhO17X4rJY6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}